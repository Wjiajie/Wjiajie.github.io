<!DOCTYPE html>
<html lang="zh-CN">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.109.0"><meta name="theme-color" content="#fff" />
    <meta name="color-scheme" content="light dark">

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>TensorRT学习笔记 | W</title>

    <link rel="stylesheet" href="/css/meme.min.f694ecb248990c1307435cb6aa04a8e886bb1e065218bdd0b4f293ed3e681f23.css"/>

    
    
        <script src="https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js" defer></script><script src="/js/meme.min.d8d173e627fe32e2218852ae80f101216ff3cd58276e147d6f46c5dd245f9040.js"></script>

    

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM&#43;Plex&#43;Serif:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;family=Comfortaa:wght@700&amp;display=swap" media="print" onload="this.media='all'" />
        <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM&#43;Plex&#43;Serif:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;family=Comfortaa:wght@700&amp;display=swap" /></noscript>

    <meta name="author" content="JiaJie" /><meta name="description" content="要经常参考：TensorRT开发者文档
" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="W" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="W" />
    <meta name="msapplication-starturl" content="../../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
    <link rel="canonical" href="https://wjiajie.github.io/contents/dl/tensorrt_intro/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2021-05-22T09:42:12+08:00",
        "dateModified": "2021-05-28T10:09:12+08:00",
        "url": "https://wjiajie.github.io/contents/dl/tensorrt_intro/",
        "headline": "TensorRT学习笔记",
        "description": "要经常参考：TensorRT开发者文档\n",
        "inLanguage" : "zh-CN",
        "articleSection": "contents",
        "wordCount":  5987 ,
        "image": ["https://i.loli.net/2021/03/22/piAG2VkUHz3lCyX.png","https://i.loli.net/2021/05/22/7OG5doe3h2Au9mU.png"],
        "author": {
            "@type": "Person",
            "description": "静心得意",
            "email": "3208920286@qq.com",
            "image": "https://s2.loli.net/2023/02/25/bTD9PrGNyC8kRi5.png",
            "url": "https://wjiajie.github.io/",
            "name": "JiaJie"
        },
        "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)",
        "publisher": {
            "@type": "Organization",
            "name": "W",
            "logo": {
                "@type": "ImageObject",
                "url": "https://wjiajie.github.io/icons/apple-touch-icon.png"
            },
            "url": "https://wjiajie.github.io/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://wjiajie.github.io/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary_large_image" />



    



<meta property="og:title" content="TensorRT学习笔记" />
<meta property="og:description" content="要经常参考：TensorRT开发者文档
" />
<meta property="og:url" content="https://wjiajie.github.io/contents/dl/tensorrt_intro/" />
<meta property="og:site_name" content="W" />
<meta property="og:locale" content="zh-cn" /><meta property="og:image" content="https://i.loli.net/2021/03/22/piAG2VkUHz3lCyX.png" />
<meta property="og:type" content="article" />
    <meta property="article:published_time" content="2021-05-22T09:42:12&#43;08:00" />
    <meta property="article:modified_time" content="2021-05-28T10:09:12&#43;08:00" />
    
    <meta property="article:section" content="contents" />


        <link rel="preconnect" href="https://www.google-analytics.com" crossorigin />

        


    
    <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', '');
    </script>




    
    

    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>



<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@700&amp;text=reuixiy&amp;display=swap" media="print" onload="this.media='all'" />
<noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@700&amp;text=reuixiy&amp;display=swap" /></noscript>





</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="/" class="brand">W</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        
            
        
        
        
        
            
                <li class="menu-item"><a href="https://www.phind.com/" target="_blank" rel="external noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon link"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg><span class="menu-item-name">桥</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/tags/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon wpexplorer"><path d="M512 256c0 141.2-114.7 256-256 256C114.8 512 0 397.3 0 256S114.7 0 256 0s256 114.7 256 256zm-32 0c0-123.2-100.3-224-224-224C132.5 32 32 132.5 32 256s100.5 224 224 224 224-100.5 224-224zM160.9 124.6l86.9 37.1-37.1 86.9-86.9-37.1 37.1-86.9zm110 169.1l46.6 94h-14.6l-50-100-48.9 100h-14l51.1-106.9-22.3-9.4 6-14 68.6 29.1-6 14.3-16.5-7.1zm-11.8-116.3l68.6 29.4-29.4 68.3L230 246l29.1-68.6zm80.3 42.9l54.6 23.1-23.4 54.3-54.3-23.1 23.1-54.3z"/></svg><span class="menu-item-name">建筑群</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="https://afdian.net/a/jiajiewu" target="_blank" rel="external noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" class="icon eye"><path d="M288 144a110.94 110.94 0 0 0-31.24 5 55.4 55.4 0 0 1 7.24 27 56 56 0 0 1-56 56 55.4 55.4 0 0 1-27-7.24A111.71 111.71 0 1 0 288 144zm284.52 97.4C518.29 135.59 410.93 64 288 64S57.68 135.64 3.48 241.41a32.35 32.35 0 0 0 0 29.19C57.71 376.41 165.07 448 288 448s230.32-71.64 284.52-177.41a32.35 32.35 0 0 0 0-29.19zM288 400c-98.65 0-189.09-55-237.93-144C98.91 167 189.34 112 288 112s189.09 55 237.93 144C477.1 345 386.66 400 288 400z"/></svg><span class="menu-item-name">发电小店</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5l48.8-97.5a18 18 0 0128 0l48.8 97.5 103.4 -34.5a18 18 0 0119.8 19.8l-34.5 103.4l97.5 48.8a18 18 0 010 28l-97.5 48.8 34.5 103.4a18 18 0 01-19.8 19.8l-103.4-34.5-48.8 97.5a18 18 0 01-28 0l-48.8-97.5l-103.4 34.5a18 18 0 01-19.8-19.8l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8-34.5-103.4a18 18 0 0119.8-19.8zM256 128a128 128 0 10.01 0M256 160a96 96 0 10.01 0"/></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412a256 256 0 10154-407a11.5 11.5 0 00-5 20a201.5 201.5 0 01-134 374a11.5 11.5 0 00-15 13"/></svg></a>
                        </li>
                    
                
            
        
            
                
            
        
            
                <li class="menu-item search-item">
                        <form id="search" class="search" role="search">
    <label for="search-input"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon search-icon"><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></label>
    <input type="search" id="search-input" class="search-input">
</form>

<template id="search-result" hidden>
    <article class="content post">
        <h2 class="post-title"><a class="summary-title-link"></a></h2>
        <summary class="summary"></summary>
        <div class="read-more-container">
            <a class="read-more-link"> »</a>
        </div>
    </article>
</template>

                    </li>
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            
    <input type="checkbox" id="nav-toggle" aria-hidden="true" />
    <label for="nav-toggle" class="nav-toggle"></label>
    <label for="nav-toggle" class="nav-curtain"></label>


        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-small-caps="true" data-align="justify" data-type="contents" data-toc-num="true">

            <h1 class="post-title p-name">TensorRT学习笔记</h1>

            

            

            
                

<div class="post-meta">
    
        
        <time datetime="2021-05-22T09:42:12&#43;08:00" class="post-meta-item published dt-published"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6 0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48c26.5 0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"/></svg>&nbsp;2021.5.22</time>
    
    
        
        <time datetime="2021-05-28T10:09:12&#43;08:00" class="post-meta-item modified dt-updated"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M400 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H48C21.49 64 0 85.49 0 112v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 400H54a6 6 0 0 1-6-6V160h352v298a6 6 0 0 1-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"/></svg>&nbsp;2021.5.28</time>
    
    
    
        
        
            
            
                
                
                
                
                    
                    
                    
                        
                            
                            
                        
                    
                
            
            
            
                <span class="post-meta-item category"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>&nbsp;<a href="/contents/dl/" class="category-link p-category">contents\DL\</a></span>
            
        
        
    
    
        
        <span class="post-meta-item wordcount"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;5987</span>
    
    
        
        <span class="post-meta-item reading-time"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;12&nbsp;</span>
    
    
        
            
            <span class="post-meta-item busuanzi-page-pv" id="busuanzi_container_page_pv"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" class="icon post-meta-icon"><path d="M288 144a110.94 110.94 0 0 0-31.24 5 55.4 55.4 0 0 1 7.24 27 56 56 0 0 1-56 56 55.4 55.4 0 0 1-27-7.24A111.71 111.71 0 1 0 288 144zm284.52 97.4C518.29 135.59 410.93 64 288 64S57.68 135.64 3.48 241.41a32.35 32.35 0 0 0 0 29.19C57.71 376.41 165.07 448 288 448s230.32-71.64 284.52-177.41a32.35 32.35 0 0 0 0-29.19zM288 400c-98.65 0-189.09-55-237.93-144C98.91 167 189.34 112 288 112s189.09 55 237.93 144C477.1 345 386.66 400 288 400z"/></svg>&nbsp;<span id="busuanzi_value_page_pv"></span></span>
        
    
    
</div>

            

            <nav class="contents">
  <h2 id="contents" class="contents-title"></h2><ol class="toc">
    <li>
      <ol>
        <li><a id="contents:tensorrt-介绍" href="#tensorrt-介绍">TensorRT 介绍</a></li>
        <li><a id="contents:tensorrt工作流程" href="#tensorrt工作流程">TensorRT工作流程</a></li>
        <li><a id="contents:tensorrt-sampleonnxmnist-解读" href="#tensorrt-sampleonnxmnist-解读">TensorRT SampleOnnxMNIST 解读</a>
          <ol>
            <li><a id="contents:sampleonnxmnist解读" href="#sampleonnxmnist解读">SampleOnnxMNIST解读</a></li>
            <li><a id="contents:精度比较" href="#精度比较">精度比较</a></li>
          </ol>
        </li>
        <li><a id="contents:tensorrt自定义算子" href="#tensorrt自定义算子">TensorRT自定义算子</a>
          <ol>
            <li><a id="contents:如何添加自定义算子" href="#如何添加自定义算子">如何添加自定义算子</a></li>
            <li><a id="contents:example-adding-a-custom-layer-using-c" href="#example-adding-a-custom-layer-using-c">Example: Adding A Custom Layer Using C++</a></li>
            <li><a id="contents:注册" href="#注册">注册</a></li>
            <li><a id="contents:调用" href="#调用">调用</a></li>
            <li><a id="contents:example-adding-a-custom-layer-with-dynamic-shape-support-using-c动态shape" href="#example-adding-a-custom-layer-with-dynamic-shape-support-using-c动态shape">Example: Adding A Custom Layer With Dynamic Shape Support Using C++(动态shape)</a></li>
            <li><a id="contents:一个plugin的例子" href="#一个plugin的例子">一个plugin的例子</a></li>
          </ol>
        </li>
        <li><a id="contents:onnx-tensorrt中的plugin注册" href="#onnx-tensorrt中的plugin注册">onnx-tensorrt中的plugin注册</a></li>
        <li><a id="contents:更多--工具和官方文档" href="#更多--工具和官方文档">更多&ndash;工具和官方文档</a></li>
        <li><a id="contents:值得仔细研读的工程" href="#值得仔细研读的工程">值得仔细研读的工程</a></li>
      </ol>
    </li>
  </ol>
</nav><div class="post-body e-content">
                <p>要经常参考：<a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html" target="_blank" rel="noopener">TensorRT开发者文档</a></p>
<h3 id="tensorrt-介绍"><a href="#tensorrt-介绍" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:tensorrt-介绍" class="headings">TensorRT 介绍</a></h3>
<p>下载TensorRT:</p>
<p>从 <a href="https://developer.nvidia.com/zh-cn/tensorrt" target="_blank" rel="noopener">这个链接</a>下载<code>tar包</code>后解压，添加环境变量：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">vim</span> <span class="o">~/</span><span class="p">.</span><span class="n">bashrc</span>
</span></span><span class="line"><span class="cl"><span class="cp"># 添加以下内容
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="k">export</span> <span class="n">LD_LIBRARY_PATH</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">TensorRT</span><span class="o">-</span><span class="mf">7.2.3.4</span><span class="o">/</span><span class="nl">lib</span><span class="p">:</span><span class="err">$</span><span class="n">LD_LIBRARY_PATH</span>
</span></span><span class="line"><span class="cl"><span class="k">export</span> <span class="n">LIBRARY_PATH</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">TensorRT</span><span class="o">-</span><span class="mf">7.2.3.4</span><span class="o">/</span><span class="n">lib</span><span class="o">::</span><span class="err">$</span><span class="n">LIBRARY_PATH</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>具体参考<a href="https://mp.weixin.qq.com/s?__biz=Mzg3ODU2MzY5MA==&amp;mid=2247487240&amp;idx=1&amp;sn=7b1a19870921d1fddf3cb8fb2653b3e3&amp;chksm=cf10970df8671e1b88fa8574ff889a158feaf797b54d695ae774831b711e0383d85b2b6cc91c&amp;mpshare=1&amp;scene=1&amp;srcid=0522ufjbKIxxt4clUpuKYE5U&amp;sharer_sharetime=1621647925203&amp;sharer_shareid=074658600bdf7eeea01216f095543d86&amp;exportkey=A7XjXiSlEEuszQzOjwhFg0M%3D&amp;pass_ticket=Un%2FZoYoqmQPv%2BX63KBgdw%2B05PHulTG%2FuayVGBo1kP6iyGo08P7EjgmL8xsTkUqFG&amp;wx_header=0#rd" target="_blank" rel="noopener">内卷成啥了还不知道TensorRT？超详细入门指北，来看看吧！</a></p>
<p>TensorRT的工作流程分为五个步骤：</p>
<p>导出模型&ndash;&gt;选择推断的batch size&ndash;&gt;选择精度&ndash;&gt;转换模型&ndash;&gt;部署模型</p>
<p><img src="https://i.loli.net/2021/03/22/piAG2VkUHz3lCyX.png" alt="Screenshot from 2021-03-22 20-56-12.png"><span class="caption">◎ 步骤</span></p>
<p><a href="https://www.notion.so/TensorRT-8a9a9997cc694735af9e62575cd4e900#e735db5990844b1f942e3b349b52a468" target="_blank" rel="noopener"></a></p>
<p>要将pytorch模型转为trt模型有两个方法：</p>
<ul>
<li>automatic ONNX conversion from .onnx files</li>
</ul>
<p>当遇到trt不支持的op时，需要手写插件。</p>
<p>pytorch模型转换为onnx模型:</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torchvision</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">torch_model_path</span> <span class="o">=</span> <span class="s2">&#34;./checkpoints/res50.pth&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">export_onnx_path</span> <span class="o">=</span> <span class="s2">&#34;./checkpoints/model.onnx&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cuda&#34;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&#34;cpu&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">torch_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">torch_model_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch_model</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="c1">#set the model to inference mode</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1">#批处理大小</span>
</span></span><span class="line"><span class="cl"><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>   <span class="c1">#输入数据,改成自己的输入shape</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>	<span class="c1"># 生成张量</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;y shape: &#34;</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="c1"># 定义的模型</span>
</span></span><span class="line"><span class="cl">                    <span class="n">x</span><span class="p">,</span> <span class="c1"># 输入数据</span>
</span></span><span class="line"><span class="cl">                    <span class="n">export_onnx_path</span><span class="p">,</span> <span class="c1"># 导出路径</span>
</span></span><span class="line"><span class="cl">                    <span class="n">opset_version</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="c1">#opset_version和onnx版本有对应关系</span>
</span></span><span class="line"><span class="cl">                    <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>	<span class="c1"># 是否执行常量折叠优化</span>
</span></span><span class="line"><span class="cl">                    <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;input&#34;</span><span class="p">],</span>	<span class="c1"># 输入名</span>
</span></span><span class="line"><span class="cl">                    <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;output&#34;</span><span class="p">],</span>	<span class="c1"># 输出名</span>
</span></span><span class="line"><span class="cl">                    <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>    <span class="c1"># 开启 verbose方便调试               </span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>可以利用<code>netron</code>来可视化导出的<code>onnx</code>模型。</p>
<pre tabindex="0"><code>pip install netron

netron
</code></pre><p>注意输入输出的名称。</p>
<p>然后利用<code>onnxruntime</code>验证导出模型是不是正确的：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">onnx</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">onnxruntime</span> <span class="k">as</span> <span class="nn">rt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model_path</span> <span class="o">=</span> <span class="s2">&#34;./checkpoints/model.onnx&#34;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 验证模型合法性</span>
</span></span><span class="line"><span class="cl"><span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">onnx</span><span class="o">.</span><span class="n">checker</span><span class="o">.</span><span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 设置模型session以及输入信息</span>
</span></span><span class="line"><span class="cl"><span class="n">sess</span> <span class="o">=</span> <span class="n">rt</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">input_name</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span></span><span class="line"><span class="cl"><span class="n">output_name</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>  
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input Name:&#39;</span><span class="p">,</span> <span class="n">input_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Output Name:&#39;</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 输入数据并调整为输入维度</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">x</span><span class="p">})</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p><code>onnx</code>模型转为<code>trt</code>模型：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">trtexec</span> <span class="o">--</span><span class="n">onnx</span><span class="o">=</span><span class="n">path_to</span><span class="o">/</span><span class="n">model</span><span class="p">.</span><span class="n">onnx</span> <span class="o">--</span><span class="n">saveEngine</span><span class="o">=</span><span class="n">path_to</span><span class="o">/</span><span class="n">resnet_engine</span><span class="p">.</span><span class="n">trt</span> <span class="o">--</span><span class="n">explicitBatch</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>上面的命令将<code>onnx</code>转为<code>trt</code>模型并且序列化到文件中了。后续可以调用<code>python</code>或者<code>c++</code>api来反序列化<code>.trt</code>文件转为<code>runtime</code>模型，速度会比先解析<code>onnx</code>模型为<code>trt</code>模型再运行要快。</p>
<p>如果要支持动态尺度，这样写：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="p">.</span><span class="o">/</span><span class="n">trtexec</span> <span class="o">--</span><span class="n">explicitBatch</span> <span class="o">--</span><span class="n">onnx</span><span class="o">=</span><span class="n">demo</span><span class="p">.</span><span class="n">onnx</span> <span class="o">--</span><span class="n">minShapes</span><span class="o">=</span><span class="nl">input</span><span class="p">:</span><span class="mi">1</span><span class="n">x1x256x256</span> <span class="o">--</span><span class="n">optShapes</span><span class="o">=</span><span class="nl">input</span><span class="p">:</span><span class="mi">1</span><span class="n">x1x2048x2048</span> <span class="o">--</span><span class="n">maxShapes</span><span class="o">=</span><span class="nl">input</span><span class="p">:</span><span class="mi">1</span><span class="n">x1x2560x2560</span> <span class="o">--</span><span class="n">shapes</span><span class="o">=</span><span class="nl">input</span><span class="p">:</span><span class="mi">1</span><span class="n">x1x2048x2048</span> <span class="o">--</span><span class="n">saveEngine</span><span class="o">=</span><span class="n">demo</span><span class="p">.</span><span class="n">trt</span> <span class="o">--</span><span class="n">workspace</span><span class="o">=</span><span class="mi">6000</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><blockquote>
<p>动态尺度支持NCHW中的N、H以及W，也就是batch、高以及宽。
对于动态模型，我们在转换模型的时候需要额外指定三个维度信息即可(最小、最优、最大)。</p>
</blockquote>
<p>TensorRT 对网络模型做了算子融合、动态显存分配、精度校准、多steam流、自动调优等操作，在很多模型上推理速度大大提升。</p>
<ul>
<li>manually constructing a network using the TensorRT API (either in C++ or Python)</li>
</ul>
<p>第二种方法更灵活(当然也更难), 这个方法我还在探索中。</p>
<h3 id="tensorrt工作流程"><a href="#tensorrt工作流程" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:tensorrt工作流程" class="headings">TensorRT工作流程</a></h3>
<p><img src="https://i.loli.net/2021/05/22/7OG5doe3h2Au9mU.png" alt="Screenshot from 2021-05-22 17-21-31.png"><span class="caption">◎ 工作流程</span></p>
<p>不管是借助<code>onnx</code>通过<code>parser</code>转为到<code>trt</code>模型，还是手工通过API搭建网络加载参数，整个运行流程可以分为下面几个步骤：</p>
<ol>
<li>创建builder(build)</li>
</ol>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"> <span class="n">IBuilder</span><span class="o">*</span> <span class="n">builder</span> <span class="o">=</span> <span class="n">createInferBuilder</span><span class="p">(</span><span class="n">gLogger</span><span class="p">);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p><code>gLogger</code>通过下面的方式来创建：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Logger</span> <span class="o">:</span> <span class="k">public</span> <span class="n">ILogger</span>           
</span></span><span class="line"><span class="cl"> <span class="p">{</span>
</span></span><span class="line"><span class="cl">     <span class="kt">void</span> <span class="nf">log</span><span class="p">(</span><span class="n">Severity</span> <span class="n">severity</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">msg</span><span class="p">)</span> <span class="k">override</span>
</span></span><span class="line"><span class="cl">     <span class="p">{</span>
</span></span><span class="line"><span class="cl">         <span class="c1">// suppress info-level messages
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>         <span class="k">if</span> <span class="p">(</span><span class="n">severity</span> <span class="o">!=</span> <span class="n">Severity</span><span class="o">::</span><span class="n">kINFO</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">             <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">msg</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">     <span class="p">}</span>
</span></span><span class="line"><span class="cl"> <span class="p">}</span> <span class="n">gLogger</span><span class="p">;</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><ol start="2">
<li>创建 engine</li>
</ol>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">IBuilderConfig</span><span class="o">*</span> <span class="n">config</span> <span class="o">=</span> <span class="n">builder</span><span class="o">-&gt;</span><span class="n">createBuilderConfig</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="c1">//这里的空间大小需要根据具体需求设置
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">config</span><span class="o">-&gt;</span><span class="n">setMaxWorkspaceSize</span><span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">20</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">ICudaEngine</span><span class="o">*</span> <span class="n">engine</span> <span class="o">=</span> <span class="n">builder</span><span class="o">-&gt;</span><span class="n">buildEngineWithConfig</span><span class="p">(</span><span class="o">*</span><span class="n">network</span><span class="p">,</span> <span class="o">*</span><span class="n">config</span><span class="p">);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>其中的<code>network</code>可以通过<code>parser</code>或者手动装载的方式实现， 比如通过<code>onnx</code>：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">const</span> <span class="k">auto</span> <span class="n">explicitBatch</span> <span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">uint32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">NetworkDefinitionCreationFlag</span><span class="o">::</span><span class="n">kEXPLICIT_BATCH</span><span class="p">);</span>  
</span></span><span class="line"><span class="cl"><span class="n">INetworkDefinition</span><span class="o">*</span> <span class="n">network</span> <span class="o">=</span> <span class="n">builder</span><span class="o">-&gt;</span><span class="n">createNetworkV2</span><span class="p">(</span><span class="n">explicitBatch</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">nvonnxparser</span><span class="o">::</span><span class="n">IParser</span><span class="o">*</span> <span class="n">parser</span> <span class="o">=</span> 
</span></span><span class="line"><span class="cl"><span class="n">nvonnxparser</span><span class="o">::</span><span class="n">createParser</span><span class="p">(</span><span class="o">*</span><span class="n">network</span><span class="p">,</span> <span class="n">gLogger</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">parser</span><span class="o">-&gt;</span><span class="n">parseFromFile</span><span class="p">(</span><span class="n">onnx_filename</span><span class="p">,</span> <span class="n">ILogger</span><span class="o">::</span><span class="n">Severity</span><span class="o">::</span><span class="n">kWARNING</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">parser</span><span class="p">.</span><span class="n">getNbErrors</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">parser</span><span class="o">-&gt;</span><span class="n">getError</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">desc</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>或者手动装载：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">INetworkDefinition</span><span class="o">*</span> <span class="n">m_network</span> <span class="o">=</span> <span class="n">builder</span><span class="o">-&gt;</span><span class="n">createNetworkV2</span><span class="p">(</span><span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">uint32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">NetworkDefinitionCreationFlag</span><span class="o">::</span><span class="n">kEXPLICIT_BATCH</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"> <span class="c1">// tensor
</span></span></span><span class="line"><span class="cl"><span class="c1"></span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">ITensor</span> <span class="o">*</span><span class="n">input</span> <span class="o">=</span> <span class="n">m_network</span><span class="o">-&gt;</span><span class="n">addInput</span><span class="p">(</span><span class="s">&#34;data&#34;</span><span class="p">,</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kFLOAT</span><span class="p">,</span>     <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DimsCHW</span><span class="p">{</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_c</span><span class="p">),</span>                             				 <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_h</span><span class="p">),</span>                                                <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_w</span><span class="p">)});</span>
</span></span><span class="line"><span class="cl"><span class="n">Layers</span><span class="p">[</span><span class="s">&#34;input&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="c1">//...很长的网络定义
</span></span></span><span class="line"><span class="cl"><span class="c1">//...
</span></span></span><span class="line"><span class="cl"><span class="c1">//...
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">Layers</span><span class="p">[</span><span class="s">&#34;relu_eng&#34;</span><span class="p">]</span> <span class="o">-&gt;</span><span class="n">setName</span><span class="p">(</span><span class="s">&#34;output1&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">m_network</span><span class="o">-&gt;</span><span class="n">markOutput</span><span class="p">(</span><span class="o">*</span><span class="n">Layers</span><span class="p">[</span><span class="s">&#34;relu_eng&#34;</span><span class="p">]);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><ol start="3">
<li>序列化到磁盘下(这一步不是必须的)</li>
</ol>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">nvinfer1</span><span class="o">::</span><span class="n">IHostMemory</span> <span class="o">*</span><span class="n">serializedModel</span> <span class="o">=</span> <span class="n">engine</span><span class="o">-&gt;</span><span class="n">serialize</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">ofstream</span> <span class="n">engFile</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">engFile</span><span class="p">.</span><span class="n">open</span><span class="p">(</span><span class="n">engPath</span><span class="p">,</span><span class="n">ios_base</span><span class="o">::</span><span class="n">binary</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">engFile</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">char</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">serializedModel</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">()),</span><span class="n">serializedModel</span><span class="o">-&gt;</span><span class="n">size</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">    <span class="n">engFile</span><span class="p">.</span><span class="n">close</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="p">...</span>
</span></span><span class="line"><span class="cl">    <span class="n">network</span><span class="o">-&gt;</span><span class="n">destroy</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">engine</span><span class="o">-&gt;</span><span class="n">destroy</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">builder</span><span class="o">-&gt;</span><span class="n">destroy</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">serializedModel</span><span class="o">-&gt;</span><span class="n">destroy</span><span class="p">();</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><ol start="4">
<li>反序列化(这一步也不是必须的)</li>
</ol>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">IRuntime</span><span class="o">*</span> <span class="n">runtime</span> <span class="o">=</span> <span class="n">createInferRuntime</span><span class="p">(</span><span class="n">gLogger</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">ICudaEngine</span><span class="o">*</span> <span class="n">engine</span> <span class="o">=</span> <span class="n">runtime</span><span class="o">-&gt;</span><span class="n">deserializeCudaEngine</span><span class="p">(</span><span class="n">modelData</span><span class="p">,</span> <span class="n">modelSize</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><ol start="5">
<li>执行推断(infer)</li>
</ol>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="c1">// 创建 RAII buffer 用于管理数据对象
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">samplesCommon</span><span class="o">::</span><span class="n">BufferManager</span> <span class="n">buffers</span><span class="p">(</span><span class="n">mEngine</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="c1">//context用于保存网络定义和训练参数等
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">IExecutionContext</span> <span class="o">*</span><span class="n">context</span> <span class="o">=</span> <span class="n">engine</span><span class="o">-&gt;</span><span class="n">createExecutionContext</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="c1">//管理输入数据的buffer:输入数据拷贝到buffer中方便管理
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="n">context</span><span class="o">-&gt;</span><span class="n">executeV2</span><span class="p">(</span><span class="n">buffers</span><span class="p">.</span><span class="n">getDeviceBindings</span><span class="p">().</span><span class="n">data</span><span class="p">());</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h3 id="tensorrt-sampleonnxmnist-解读"><a href="#tensorrt-sampleonnxmnist-解读" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:tensorrt-sampleonnxmnist-解读" class="headings">TensorRT SampleOnnxMNIST 解读</a></h3>
<p>首先编写<code>CMakeLists.txt</code>:</p>
<pre tabindex="0"><code class="language-TXT" data-lang="TXT">cmake_minimum_required(VERSION 2.8)

project(sampleOnnxMNIST)

set(CMAKE_CXX_FLAGS &#34;${CAMKE_CXX_FLAGS} -std=c++11 -pthread&#34;)

find_package(CUDA REQUIRED)
include_directories(/usr/local/cuda/include)
link_directories(/usr/local/cuda/lib64)

include_directories(../common)
aux_source_directory(../common SRC_LIST)
# tensorrt
include_directories(/home/jiajie/Learn/TensorRT-7.2.1.61/include/)
link_directories(/home/jiajie/Learn/TensorRT-7.2.1.61/lib/)

find_package(OpenCV)
include_directories(OpenCV_INCLUDE_DIRS)

link_libraries(&#34;/home/jiajie/Learn/TensorRT-7.2.1.61/targets/x86_64-linux-gnu/lib/libnvonnxparser.so&#34;)
link_libraries(&#34;/home/jiajie/Learn/TensorRT-7.2.1.61/targets/x86_64-linux-gnu/lib/libnvcaffe_parser.so&#34;)

add_executable(sampleOnnxMNIST ${PROJECT_SOURCE_DIR}/sampleOnnxMNIST.cpp ${SRC_LIST})
target_link_libraries(sampleOnnxMNIST nvinfer)
target_link_libraries(sampleOnnxMNIST cudart)
target_link_libraries(sampleOnnxMNIST ${OpenCV_LIBS})
</code></pre><h4 id="sampleonnxmnist解读"><a href="#sampleonnxmnist解读" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:sampleonnxmnist解读" class="headings">SampleOnnxMNIST解读</a></h4>
<p>按照上面TensorRT工作流程， SampleOnnxMNIST只是在这基础上加了很多logging的代码还有代码稳健性的检查，同时没有上面步骤中的序列化到磁盘的步骤。</p>
<p>首先看<code>main()</code>函数：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//1. 传参和gLogger，先不用扣细节
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">samplesCommon</span><span class="o">::</span><span class="n">Args</span> <span class="n">args</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">bool</span> <span class="n">argsOK</span> <span class="o">=</span> <span class="n">samplesCommon</span><span class="o">::</span><span class="n">parseArgs</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">argc</span><span class="p">,</span> <span class="n">argv</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">argsOK</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">sample</span><span class="o">::</span><span class="n">gLogError</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Invalid arguments&#34;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">printHelpInfo</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">EXIT_FAILURE</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">help</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">printHelpInfo</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">EXIT_SUCCESS</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">auto</span> <span class="n">sampleTest</span> <span class="o">=</span> <span class="n">sample</span><span class="o">::</span><span class="n">gLogger</span><span class="p">.</span><span class="n">defineTest</span><span class="p">(</span><span class="n">gSampleName</span><span class="p">,</span> <span class="n">argc</span><span class="p">,</span> <span class="n">argv</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">sample</span><span class="o">::</span><span class="n">gLogger</span><span class="p">.</span><span class="n">reportTestStart</span><span class="p">(</span><span class="n">sampleTest</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//2. 创建SampleOnnxMNIST对象并初始化参数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">SampleOnnxMNIST</span> <span class="n">sample</span><span class="p">(</span><span class="n">initializeSampleParams</span><span class="p">(</span><span class="n">args</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">sample</span><span class="o">::</span><span class="n">gLogInfo</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Building and running a GPU inference engine for Onnx MNIST&#34;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//3. 构建trt引擎
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">sample</span><span class="p">.</span><span class="n">build</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">sample</span><span class="o">::</span><span class="n">gLogger</span><span class="p">.</span><span class="n">reportFail</span><span class="p">(</span><span class="n">sampleTest</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//执行推断
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">sample</span><span class="p">.</span><span class="n">infer</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">sample</span><span class="o">::</span><span class="n">gLogger</span><span class="p">.</span><span class="n">reportFail</span><span class="p">(</span><span class="n">sampleTest</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">sample</span><span class="o">::</span><span class="n">gLogger</span><span class="p">.</span><span class="n">reportPass</span><span class="p">(</span><span class="n">sampleTest</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>第二步的<code>initializeSampleParams</code>定义了一些外部参数:</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \brief Initializes members of the params struct using the command line args
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">samplesCommon</span><span class="o">::</span><span class="n">OnnxSampleParams</span> <span class="n">initializeSampleParams</span><span class="p">(</span><span class="k">const</span> <span class="n">samplesCommon</span><span class="o">::</span><span class="n">Args</span><span class="o">&amp;</span> <span class="n">args</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">samplesCommon</span><span class="o">::</span><span class="n">OnnxSampleParams</span> <span class="n">params</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">dataDirs</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="c1">//!&lt; Use default directories if user hasn&#39;t provided directory paths
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">params</span><span class="p">.</span><span class="n">dataDirs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="s">&#34;data/mnist/&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">params</span><span class="p">.</span><span class="n">dataDirs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="s">&#34;data/samples/mnist/&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">params</span><span class="p">.</span><span class="n">dataDirs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="s">&#34;/home/jiajie/baidunetdiskdownload/Find_a_job/Learn_tensorRT/practice/data/mnist/&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span> <span class="c1">//!&lt; Use the data directory provided by the user
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">params</span><span class="p">.</span><span class="n">dataDirs</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">dataDirs</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">params</span><span class="p">.</span><span class="n">onnxFileName</span> <span class="o">=</span> <span class="s">&#34;mnist.onnx&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">params</span><span class="p">.</span><span class="n">inputTensorNames</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="s">&#34;Input3&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">params</span><span class="p">.</span><span class="n">outputTensorNames</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="s">&#34;Plus214_Output_0&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">params</span><span class="p">.</span><span class="n">dlaCore</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">useDLACore</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">params</span><span class="p">.</span><span class="n">int8</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">runInInt8</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">params</span><span class="p">.</span><span class="n">fp16</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">runInFp16</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">params</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>再看第三步<code>build</code>就很清晰了：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \brief Creates the network, configures the builder and creates the network engine
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \details This function creates the Onnx MNIST network by parsing the Onnx model and builds
</span></span></span><span class="line"><span class="cl"><span class="c1">//!          the engine that will be used to run MNIST (mEngine)
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \return Returns true if the engine was created successfully and false otherwise
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">bool</span> <span class="n">SampleOnnxMNIST</span><span class="o">::</span><span class="n">build</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//创建builder
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">auto</span> <span class="n">builder</span> <span class="o">=</span> <span class="n">SampleUniquePtr</span><span class="o">&lt;</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">IBuilder</span><span class="o">&gt;</span><span class="p">(</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">createInferBuilder</span><span class="p">(</span><span class="n">sample</span><span class="o">::</span><span class="n">gLogger</span><span class="p">.</span><span class="n">getTRTLogger</span><span class="p">()));</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">builder</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="k">auto</span> <span class="n">explicitBatch</span> <span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">uint32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">NetworkDefinitionCreationFlag</span><span class="o">::</span><span class="n">kEXPLICIT_BATCH</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//创建network
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">auto</span> <span class="n">network</span> <span class="o">=</span> <span class="n">SampleUniquePtr</span><span class="o">&lt;</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">INetworkDefinition</span><span class="o">&gt;</span><span class="p">(</span><span class="n">builder</span><span class="o">-&gt;</span><span class="n">createNetworkV2</span><span class="p">(</span><span class="n">explicitBatch</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">network</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">auto</span> <span class="n">config</span> <span class="o">=</span> <span class="n">SampleUniquePtr</span><span class="o">&lt;</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">IBuilderConfig</span><span class="o">&gt;</span><span class="p">(</span><span class="n">builder</span><span class="o">-&gt;</span><span class="n">createBuilderConfig</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">auto</span> <span class="n">parser</span>
</span></span><span class="line"><span class="cl">        <span class="o">=</span> <span class="n">SampleUniquePtr</span><span class="o">&lt;</span><span class="n">nvonnxparser</span><span class="o">::</span><span class="n">IParser</span><span class="o">&gt;</span><span class="p">(</span><span class="n">nvonnxparser</span><span class="o">::</span><span class="n">createParser</span><span class="p">(</span><span class="o">*</span><span class="n">network</span><span class="p">,</span> <span class="n">sample</span><span class="o">::</span><span class="n">gLogger</span><span class="p">.</span><span class="n">getTRTLogger</span><span class="p">()));</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">parser</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//用parser的方式构造网络
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">auto</span> <span class="n">constructed</span> <span class="o">=</span> <span class="n">constructNetwork</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">parser</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">constructed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//buildEngineWithConfig
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">mEngine</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">ICudaEngine</span><span class="o">&gt;</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">builder</span><span class="o">-&gt;</span><span class="n">buildEngineWithConfig</span><span class="p">(</span><span class="o">*</span><span class="n">network</span><span class="p">,</span> <span class="o">*</span><span class="n">config</span><span class="p">),</span> <span class="n">samplesCommon</span><span class="o">::</span><span class="n">InferDeleter</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">mEngine</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">assert</span><span class="p">(</span><span class="n">network</span><span class="o">-&gt;</span><span class="n">getNbInputs</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">mInputDims</span> <span class="o">=</span> <span class="n">network</span><span class="o">-&gt;</span><span class="n">getInput</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">getDimensions</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">assert</span><span class="p">(</span><span class="n">mInputDims</span><span class="p">.</span><span class="n">nbDims</span> <span class="o">==</span> <span class="mi">4</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">assert</span><span class="p">(</span><span class="n">network</span><span class="o">-&gt;</span><span class="n">getNbOutputs</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">mOutputDims</span> <span class="o">=</span> <span class="n">network</span><span class="o">-&gt;</span><span class="n">getOutput</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">getDimensions</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">assert</span><span class="p">(</span><span class="n">mOutputDims</span><span class="p">.</span><span class="n">nbDims</span> <span class="o">==</span> <span class="mi">2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>其中的<code>constructNetwork</code>是：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \brief Uses a ONNX parser to create the Onnx MNIST Network and marks the
</span></span></span><span class="line"><span class="cl"><span class="c1">//!        output layers
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \param network Pointer to the network that will be populated with the Onnx MNIST network
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \param builder Pointer to the engine builder
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">bool</span> <span class="n">SampleOnnxMNIST</span><span class="o">::</span><span class="n">constructNetwork</span><span class="p">(</span><span class="n">SampleUniquePtr</span><span class="o">&lt;</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">IBuilder</span><span class="o">&gt;&amp;</span> <span class="n">builder</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">SampleUniquePtr</span><span class="o">&lt;</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">INetworkDefinition</span><span class="o">&gt;&amp;</span> <span class="n">network</span><span class="p">,</span> <span class="n">SampleUniquePtr</span><span class="o">&lt;</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">IBuilderConfig</span><span class="o">&gt;&amp;</span> <span class="n">config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">SampleUniquePtr</span><span class="o">&lt;</span><span class="n">nvonnxparser</span><span class="o">::</span><span class="n">IParser</span><span class="o">&gt;&amp;</span> <span class="n">parser</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">auto</span> <span class="n">parsed</span> <span class="o">=</span> <span class="n">parser</span><span class="o">-&gt;</span><span class="n">parseFromFile</span><span class="p">(</span><span class="n">locateFile</span><span class="p">(</span><span class="n">mParams</span><span class="p">.</span><span class="n">onnxFileName</span><span class="p">,</span> <span class="n">mParams</span><span class="p">.</span><span class="n">dataDirs</span><span class="p">).</span><span class="n">c_str</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sample</span><span class="o">::</span><span class="n">gLogger</span><span class="p">.</span><span class="n">getReportableSeverity</span><span class="p">()));</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">parsed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">config</span><span class="o">-&gt;</span><span class="n">setMaxWorkspaceSize</span><span class="p">(</span><span class="mi">16</span><span class="n">_MiB</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">mParams</span><span class="p">.</span><span class="n">fp16</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">config</span><span class="o">-&gt;</span><span class="n">setFlag</span><span class="p">(</span><span class="n">BuilderFlag</span><span class="o">::</span><span class="n">kFP16</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">mParams</span><span class="p">.</span><span class="n">int8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">config</span><span class="o">-&gt;</span><span class="n">setFlag</span><span class="p">(</span><span class="n">BuilderFlag</span><span class="o">::</span><span class="n">kINT8</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">samplesCommon</span><span class="o">::</span><span class="n">setAllTensorScales</span><span class="p">(</span><span class="n">network</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span> <span class="mf">127.0f</span><span class="p">,</span> <span class="mf">127.0f</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">samplesCommon</span><span class="o">::</span><span class="n">enableDLA</span><span class="p">(</span><span class="n">builder</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span> <span class="n">config</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span> <span class="n">mParams</span><span class="p">.</span><span class="n">dlaCore</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>再看第四步<code>infer</code>：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \brief Runs the TensorRT inference engine for this sample
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \details This function is the main execution function of the sample. It allocates the buffer,
</span></span></span><span class="line"><span class="cl"><span class="c1">//!          sets inputs and executes the engine.
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">bool</span> <span class="n">SampleOnnxMNIST</span><span class="o">::</span><span class="n">infer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 创建 RAII buffer 管理数据对象
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">samplesCommon</span><span class="o">::</span><span class="n">BufferManager</span> <span class="n">buffers</span><span class="p">(</span><span class="n">mEngine</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">auto</span> <span class="n">context</span> <span class="o">=</span> <span class="n">SampleUniquePtr</span><span class="o">&lt;</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">IExecutionContext</span><span class="o">&gt;</span><span class="p">(</span><span class="n">mEngine</span><span class="o">-&gt;</span><span class="n">createExecutionContext</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">context</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Read the input data into the managed buffers
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">assert</span><span class="p">(</span><span class="n">mParams</span><span class="p">.</span><span class="n">inputTensorNames</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">processInput</span><span class="p">(</span><span class="n">buffers</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Memcpy from host input buffers to device input buffers
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">buffers</span><span class="p">.</span><span class="n">copyInputToDevice</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kt">bool</span> <span class="n">status</span> <span class="o">=</span> <span class="n">context</span><span class="o">-&gt;</span><span class="n">executeV2</span><span class="p">(</span><span class="n">buffers</span><span class="p">.</span><span class="n">getDeviceBindings</span><span class="p">().</span><span class="n">data</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">status</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Memcpy from device output buffers to host output buffers
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">buffers</span><span class="p">.</span><span class="n">copyOutputToHost</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Verify results
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">verifyOutput</span><span class="p">(</span><span class="n">buffers</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>其中<code>processInput</code>是：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \brief Reads the input and stores the result in a managed buffer
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">bool</span> <span class="n">SampleOnnxMNIST</span><span class="o">::</span><span class="n">processInput</span><span class="p">(</span><span class="k">const</span> <span class="n">samplesCommon</span><span class="o">::</span><span class="n">BufferManager</span><span class="o">&amp;</span> <span class="n">buffers</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">int</span> <span class="n">inputH</span> <span class="o">=</span> <span class="n">mInputDims</span><span class="p">.</span><span class="n">d</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">int</span> <span class="n">inputW</span> <span class="o">=</span> <span class="n">mInputDims</span><span class="p">.</span><span class="n">d</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Read a random digit file
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">srand</span><span class="p">(</span><span class="kt">unsigned</span><span class="p">(</span><span class="n">time</span><span class="p">(</span><span class="k">nullptr</span><span class="p">)));</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span> <span class="n">fileData</span><span class="p">(</span><span class="n">inputH</span> <span class="o">*</span> <span class="n">inputW</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">mNumber</span> <span class="o">=</span> <span class="n">rand</span><span class="p">()</span> <span class="o">%</span> <span class="mi">10</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">readPGMFile</span><span class="p">(</span><span class="n">locateFile</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">mNumber</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#34;.pgm&#34;</span><span class="p">,</span> <span class="n">mParams</span><span class="p">.</span><span class="n">dataDirs</span><span class="p">),</span> <span class="n">fileData</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">inputH</span><span class="p">,</span> <span class="n">inputW</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Print an ascii representation
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">sample</span><span class="o">::</span><span class="n">gLogInfo</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Input:&#34;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">inputH</span> <span class="o">*</span> <span class="n">inputW</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">sample</span><span class="o">::</span><span class="n">gLogInfo</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="s">&#34; .:-=+*#%@&#34;</span><span class="p">[</span><span class="n">fileData</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="mi">26</span><span class="p">])</span> <span class="o">&lt;&lt;</span> <span class="p">(((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">inputW</span><span class="p">)</span> <span class="o">?</span> <span class="s">&#34;&#34;</span> <span class="o">:</span> <span class="s">&#34;</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">sample</span><span class="o">::</span><span class="n">gLogInfo</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kt">float</span><span class="o">*</span> <span class="n">hostDataBuffer</span> <span class="o">=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">buffers</span><span class="p">.</span><span class="n">getHostBuffer</span><span class="p">(</span><span class="n">mParams</span><span class="p">.</span><span class="n">inputTensorNames</span><span class="p">[</span><span class="mi">0</span><span class="p">]));</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">inputH</span> <span class="o">*</span> <span class="n">inputW</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">hostDataBuffer</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="kt">float</span><span class="p">(</span><span class="n">fileData</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>其中<code>verifyOutput</code>是：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \brief Classifies digits and verify result
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1">//! \return whether the classification output matches expectations
</span></span></span><span class="line"><span class="cl"><span class="c1">//!
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">bool</span> <span class="n">SampleOnnxMNIST</span><span class="o">::</span><span class="n">verifyOutput</span><span class="p">(</span><span class="k">const</span> <span class="n">samplesCommon</span><span class="o">::</span><span class="n">BufferManager</span><span class="o">&amp;</span> <span class="n">buffers</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">int</span> <span class="n">outputSize</span> <span class="o">=</span> <span class="n">mOutputDims</span><span class="p">.</span><span class="n">d</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="kt">float</span><span class="o">*</span> <span class="n">output</span> <span class="o">=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">buffers</span><span class="p">.</span><span class="n">getHostBuffer</span><span class="p">(</span><span class="n">mParams</span><span class="p">.</span><span class="n">outputTensorNames</span><span class="p">[</span><span class="mi">0</span><span class="p">]));</span>
</span></span><span class="line"><span class="cl">    <span class="kt">float</span> <span class="n">val</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">};</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">idx</span><span class="p">{</span><span class="mi">0</span><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Calculate Softmax
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">float</span> <span class="n">sum</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">};</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">outputSize</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="n">sum</span> <span class="o">+=</span> <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">sample</span><span class="o">::</span><span class="n">gLogInfo</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Output:&#34;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">outputSize</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/=</span> <span class="n">sum</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">val</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">val</span> <span class="o">==</span> <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">idx</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">sample</span><span class="o">::</span><span class="n">gLogInfo</span> <span class="o">&lt;&lt;</span> <span class="s">&#34; Prob &#34;</span> <span class="o">&lt;&lt;</span> <span class="n">i</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;  &#34;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">fixed</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">setw</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">setprecision</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                         <span class="o">&lt;&lt;</span> <span class="s">&#34; &#34;</span>
</span></span><span class="line"><span class="cl">                         <span class="o">&lt;&lt;</span> <span class="s">&#34;Class &#34;</span> <span class="o">&lt;&lt;</span> <span class="n">i</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;: &#34;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="kt">int</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">floor</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="mf">0.5f</span><span class="p">)),</span> <span class="sc">&#39;*&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                         <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">sample</span><span class="o">::</span><span class="n">gLogInfo</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">idx</span> <span class="o">==</span> <span class="n">mNumber</span> <span class="o">&amp;&amp;</span> <span class="n">val</span> <span class="o">&gt;</span> <span class="mf">0.9f</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h4 id="精度比较"><a href="#精度比较" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:精度比较" class="headings">精度比较</a></h4>
<p>通常用下面的公式做精度比较：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Python" data-lang="Python"><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y_onnx</span> <span class="o">=</span> <span class="n">model_onnx</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># check the output against PyTorch</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_trt</span><span class="p">)))</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h3 id="tensorrt自定义算子"><a href="#tensorrt自定义算子" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:tensorrt自定义算子" class="headings">TensorRT自定义算子</a></h3>
<p>文章<a href="https://mp.weixin.qq.com/s?__biz=Mzg3ODU2MzY5MA==&amp;mid=2247485335&amp;idx=1&amp;sn=e04574597077dea50dc53d1e490d82af&amp;chksm=cf109f92f8671684c1783f952f9f6c02a806766fa5f63174f58ec1a2e8fb8910f4dcaf80ef80&amp;mpshare=1&amp;scene=1&amp;srcid=05231z44VtZd7Hwctpk3wPKX&amp;sharer_sharetime=1621734167376&amp;sharer_shareid=074658600bdf7eeea01216f095543d86&amp;exportkey=A%2FjBJs%2BIKGfvV6cfAM5wwCE%3D&amp;pass_ticket=2IfqEtm%2BwWeiEY7d%2FSHyazwULRW8wMQtfvyJm9I0y4iDKB1hM5iE6mIW89v901Yt&amp;wx_header=0#rd" target="_blank" rel="noopener">实现TensorRT自定义插件(plugin)自由！</a>介绍的很详细。</p>
<h4 id="如何添加自定义算子"><a href="#如何添加自定义算子" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:如何添加自定义算子" class="headings">如何添加自定义算子</a></h4>
<ol>
<li>可以模仿官方的<code>plugin</code>库，添加自己的<code>plugin</code>后再相应的修改<code>CMakeLists.txt</code>，重新编译<code>libnvinfer_plugin.so.7</code></li>
<li>模仿官方<code>plugin</code>库的层级结构，生成一个新的<code>.so</code>，然后在自己的工程中调用它。</li>
</ol>
<h4 id="example-adding-a-custom-layer-using-c"><a href="#example-adding-a-custom-layer-using-c" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:example-adding-a-custom-layer-using-c" class="headings">Example: Adding A Custom Layer Using C++</a></h4>
<ol>
<li>要创建一个plugin自定义类， 必须继承<code>IPluginV2Ext</code>，<code>IPluginV2IOExt</code>，<code>IPluginV2DynamicExt</code>中的一个，并且重写其中的虚函数。</li>
</ol>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">FooPlugin</span> <span class="o">:</span> <span class="k">public</span> <span class="n">IPluginV2IOExt</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="p">...</span><span class="k">override</span> <span class="n">all</span> <span class="n">pure</span> <span class="k">virtual</span> <span class="n">methods</span> <span class="n">of</span> <span class="n">IPluginV2IOExt</span> <span class="n">with</span> <span class="n">definitions</span> <span class="k">for</span> <span class="n">your</span> <span class="n">plugin</span><span class="p">.</span>  <span class="n">Do</span> <span class="n">not</span> <span class="k">override</span> <span class="n">the</span> <span class="n">TRT_DEPRECATED</span> <span class="n">methods</span><span class="p">.</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><ol start="2">
<li>要实现一个工厂类<code>FooPluginCreator</code>,用于创建<code>FooPlugin</code>的实例</li>
</ol>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MyCustomPluginCreator</span> <span class="o">:</span> <span class="k">public</span> <span class="n">BaseCreator</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><blockquote>
<p>IPluginCreator is a creator class for custom layers using which users can get plugin name, version, and plugin field parameters. It also provides methods to create the plugin object during the network build phase and deserialize it during inference.</p>
</blockquote>
<blockquote>
<p>Note: In versions of TensorRT prior to 6.0.1, you derived custom layers from IPluginV2 or IPluginV2Ext. While these APIs are still supported, we highly encourage you to move to IPluginV2IOExt or IPluginV2DynamicExt to be able to use all the new plugin functionalities.</p>
</blockquote>
<blockquote>
<p>TensorRT also provides the ability to register a plugin by calling REGISTER_TENSORRT_PLUGIN(pluginCreator) which statically registers the Plugin Creator to the Plugin Registry. During runtime, the Plugin Registry can be queried using the extern function getPluginRegistry(). The Plugin Registry stores a pointer to all the registered Plugin Creators and can be used to look up a specific Plugin Creator based on the plugin name and version.</p>
</blockquote>
<h4 id="注册"><a href="#注册" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:注册" class="headings">注册</a></h4>
<p>然后通过<code>REGISTER_TENSORRT_PLUGIN(pluginCreator)</code>注册plugin（下文会涉及）.</p>
<blockquote>
<p>Note: To use TensorRT registered plugins in your application, the libnvinfer_plugin.so library must be loaded and all plugins must be registered. This can be done by calling initLibNvInferPlugins(void* logger, const char* libNamespace)() in your application code.</p>
</blockquote>
<p>或者通过<code>initLibNvInferPlugins(void* logger, const char* libNamespace)()</code>来注册。（注册的方法二选一）</p>
<h4 id="调用"><a href="#调用" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:调用" class="headings">调用</a></h4>
<blockquote>
<p>Using the Plugin Creator, the IPluginCreator::createPlugin() function can be called which returns a plugin object of type IPluginV2. This object can be added to the TensorRT network using addPluginV2() which creates and adds a layer to a network and then binds the layer to the given plugin. The method also returns a pointer to the layer (of type IPluginV2Layer), which can be used to access the layer or the plugin itself (via getPlugin()).</p>
</blockquote>
<h4 id="example-adding-a-custom-layer-with-dynamic-shape-support-using-c动态shape"><a href="#example-adding-a-custom-layer-with-dynamic-shape-support-using-c动态shape" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:example-adding-a-custom-layer-with-dynamic-shape-support-using-c动态shape" class="headings">Example: Adding A Custom Layer With Dynamic Shape Support Using C++(动态shape)</a></h4>
<p>与静态shape类似，需要重写<code>IPluginV2DynamicExt</code>中的虚函数</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">BarPlugin</span> <span class="o">:</span> <span class="k">public</span> <span class="n">IPluginV2DynamicExt</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="p">...</span><span class="k">override</span> <span class="k">virtual</span> <span class="n">methods</span> <span class="n">inherited</span> <span class="n">from</span> <span class="n">IPluginV2DynamicExt</span><span class="p">.</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h4 id="一个plugin的例子"><a href="#一个plugin的例子" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:一个plugin的例子" class="headings">一个plugin的例子</a></h4>
<p>在<code>main</code>函数的网络定义中，加入<code>plugin</code>:</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="c1">//网络的定义
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="c1">//添加plugin
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">AddPlugin</span> <span class="n">addPlugin</span><span class="p">(</span><span class="n">Weights</span><span class="p">{</span><span class="n">DataType</span><span class="o">::</span><span class="n">kFLOAT</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">valueToAdd</span><span class="p">,</span> <span class="mi">1</span><span class="p">});</span>
</span></span><span class="line"><span class="cl"><span class="n">ITensor</span> <span class="o">*</span><span class="n">aInputTensor</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span><span class="n">tensor</span><span class="p">};</span>
</span></span><span class="line"><span class="cl"><span class="c1">//调用
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">tensor</span> <span class="o">=</span> <span class="n">network</span><span class="o">-&gt;</span><span class="n">addPluginV2</span><span class="p">(</span><span class="n">aInputTensor</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">addPlugin</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">getOutput</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">network</span><span class="o">-&gt;</span><span class="n">markOutput</span><span class="p">(</span><span class="o">*</span><span class="n">tensor</span><span class="p">);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>在<code>AddPlugin.h</code>中实现<code>AddPlugin : public nvinfer1::IPluginV2IOExt</code>和它的工厂类<code>AddPluginCreator : public nvinfer1::IPluginCreator</code></p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;NvInfer.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;cstring&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;assert.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">AddPlugin</span><span class="o">:</span> <span class="k">public</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">IPluginV2IOExt</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//创建该插件时调用的构造函数，需要传递权重信息以及参数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">AddPlugin</span><span class="p">(</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">Weights</span> <span class="n">valueToAdd</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">m</span><span class="p">.</span><span class="n">valueToAdd</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">valueToAdd</span><span class="p">.</span><span class="n">values</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//可以在反序列化时，调用这个构造函数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">AddPlugin</span><span class="p">(</span><span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">buffer</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">length</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">memcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">m</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">m</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//返回序列化时需要写多少字节到buffer中。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">virtual</span> <span class="n">size_t</span> <span class="nf">getSerializationSize</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">m</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//序列化
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">serialize</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">buffer</span><span class="p">)</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">memcpy</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">m</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">m</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//拷贝函数,将这个plugin对象克隆一份给TensorRT的builder、network或者engine。(该方法会调用拷贝构造函数)
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">nvinfer1</span><span class="o">::</span><span class="n">IPluginV2IOExt</span><span class="o">*</span> <span class="n">clone</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="k">new</span> <span class="nf">AddPlugin</span><span class="p">(</span><span class="o">&amp;</span><span class="n">m</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">m</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//检查类型支持
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">//TensorRT调用此方法以判断pos索引的输入/输出是否支持inOut[pos].format和inOut[pos].type指定的格式/数据类型。
</span></span></span><span class="line"><span class="cl"><span class="c1">//如果插件支持inOut[pos]处的格式/数据类型，则返回true。如果是否支持取决于其他的输入/输出格式/数据类型，则插件可以使其结果取决于inOut[0..pos-1]中的格式/数据类型，该格式/数据类型将设置为插件支持的值。这个函数不需要检查inOut[pos + 1..nbInputs + nbOutputs-1]，pos的决定必须仅基于inOut[0..pos]。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">bool</span> <span class="nf">supportsFormatCombination</span><span class="p">(</span><span class="kt">int</span> <span class="n">pos</span><span class="p">,</span> <span class="k">const</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">PluginTensorDesc</span><span class="o">*</span> <span class="n">inOut</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nbInputs</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nbOutputs</span><span class="p">)</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    	<span class="k">switch</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    	<span class="k">case</span> <span class="mi">0</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    		<span class="n">printf</span><span class="p">(</span><span class="s">&#34;inOut[0].type = %d, format[0]=%d</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="n">inOut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">type</span><span class="p">,</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="n">inOut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">format</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    		<span class="k">return</span> 
</span></span><span class="line"><span class="cl">    			<span class="p">((</span><span class="n">inOut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">type</span> <span class="o">==</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kFLOAT</span> <span class="o">||</span> <span class="n">inOut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">type</span> <span class="o">==</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kHALF</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">inOut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">format</span> <span class="o">==</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">TensorFormat</span><span class="o">::</span><span class="n">kLINEAR</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    			<span class="o">||</span> <span class="p">(</span><span class="n">inOut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">type</span> <span class="o">==</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kINT8</span> <span class="o">&amp;&amp;</span> <span class="n">inOut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">format</span> <span class="o">==</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">TensorFormat</span><span class="o">::</span><span class="n">kCHW4</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    	<span class="k">case</span> <span class="mi">1</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    		<span class="n">printf</span><span class="p">(</span><span class="s">&#34;inOut[1].type = %d, format[1]=%d</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="n">inOut</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">type</span><span class="p">,</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="n">inOut</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">format</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    		<span class="k">return</span> <span class="n">inOut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">format</span> <span class="o">==</span> <span class="n">inOut</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">format</span> <span class="o">&amp;&amp;</span> <span class="n">inOut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">type</span> <span class="o">==</span> <span class="n">inOut</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">type</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    	<span class="p">}</span>
</span></span><span class="line"><span class="cl">    	<span class="k">return</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//返回的输出tensor数目
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span> <span class="nf">getNbOutputs</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//定义返回的输出tensor维度
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">nvinfer1</span><span class="o">::</span><span class="n">Dims</span> <span class="n">getOutputDimensions</span><span class="p">(</span><span class="kt">int</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">Dims</span><span class="o">*</span> <span class="n">pInputDim</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nInputDim</span><span class="p">)</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">pInputDim</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//返回结果的类型
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span> <span class="n">getOutputDataType</span><span class="p">(</span><span class="kt">int</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">*</span> <span class="n">inputTypes</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nbInputs</span><span class="p">)</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    	<span class="k">return</span> <span class="n">inputTypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kFLOAT</span> <span class="o">?</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="nl">kFLOAT</span> <span class="p">:</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kINT8</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//配置这个插件op，判断输入和输出类型数量是否正确。官方还提到通过这个配置信息可以告知TensorRT去选择合适的算法(algorithm)去调优这个模型。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">configurePlugin</span><span class="p">(</span><span class="k">const</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">PluginTensorDesc</span><span class="o">*</span> <span class="n">in</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nbInput</span><span class="p">,</span> <span class="k">const</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">PluginTensorDesc</span><span class="o">*</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nbOutput</span><span class="p">)</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    	<span class="n">m</span><span class="p">.</span><span class="n">dataType</span> <span class="o">=</span> <span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">type</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    	<span class="n">m</span><span class="p">.</span><span class="n">inputDim</span> <span class="o">=</span> <span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">dims</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    	<span class="n">m</span><span class="p">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">scale</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    	<span class="n">printf</span><span class="p">(</span><span class="s">&#34;configurePlugin type=%d, m.scale=%f</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">type</span><span class="p">,</span> <span class="n">m</span><span class="p">.</span><span class="n">scale</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//我们需要在这里确定这个op需要多大的显存空间去运行,尽量不要自己取申请显存空间
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">//而是让Tensorrt官方接口传过来的workspace指针来管理显存空间
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">size_t</span> <span class="nf">getWorkspaceSize</span><span class="p">(</span><span class="kt">int</span> <span class="n">nMaxBatchSize</span><span class="p">)</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span><span class="k">return</span> <span class="mi">0</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//实际插件op的执行函数，我们自己实现的cuda操作就放到这里
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//它的具体实现看下面的`AddPlugin.cu`
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span> <span class="nf">enqueue</span><span class="p">(</span><span class="kt">int</span> <span class="n">nBatch</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span> <span class="k">const</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="kt">void</span> <span class="o">**</span><span class="n">outputs</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">workspace</span><span class="p">,</span> <span class="n">cudaStream_t</span> <span class="n">stream</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="nf">initialize</span><span class="p">()</span> <span class="k">override</span> <span class="p">{</span><span class="k">return</span> <span class="mi">0</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="nf">terminate</span><span class="p">()</span> <span class="k">override</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="nf">destroy</span><span class="p">()</span> <span class="k">override</span> <span class="p">{</span> <span class="k">delete</span> <span class="k">this</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//设置插件的namespace的名字
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="nf">setPluginNamespace</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">szNamespace</span><span class="p">)</span> <span class="k">override</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//如果设置插件的namespace的名字，默认是&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="nf">getPluginNamespace</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span><span class="k">return</span> <span class="s">&#34;&#34;</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="nf">getPluginType</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span><span class="k">return</span> <span class="s">&#34;AddPlugin&#34;</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="nf">getPluginVersion</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span><span class="k">return</span> <span class="s">&#34;0&#34;</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">    <span class="kt">bool</span> <span class="nf">canBroadcastInputAcrossBatch</span><span class="p">(</span><span class="kt">int</span> <span class="n">inputIndex</span><span class="p">)</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span><span class="k">return</span> <span class="nb">false</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">    <span class="kt">bool</span> <span class="nf">isOutputBroadcastAcrossBatch</span><span class="p">(</span><span class="kt">int</span> <span class="n">outputIndex</span><span class="p">,</span> <span class="k">const</span> <span class="kt">bool</span><span class="o">*</span> <span class="n">inputIsBroadcasted</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nbInputs</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span><span class="k">return</span> <span class="nb">false</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//如果这个op使用到了一些其他东西，例如cublas handle，可以直接借助TensorRT内部提供的cublas handle:
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="nf">attachToContext</span><span class="p">(</span><span class="n">cudnnContext</span><span class="o">*</span> <span class="cm">/*cudnn*/</span><span class="p">,</span> <span class="n">cublasContext</span><span class="o">*</span> <span class="cm">/*cublas*/</span><span class="p">,</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">IGpuAllocator</span><span class="o">*</span> <span class="cm">/*allocator*/</span><span class="p">)</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="nf">detachFromContext</span><span class="p">()</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">private</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">using</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">IPluginV2Ext</span><span class="o">::</span><span class="n">configurePlugin</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">//插件中的权重、超参数定义在private里面
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">struct</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span> <span class="n">dataType</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">nvinfer1</span><span class="o">::</span><span class="n">Dims</span> <span class="n">inputDim</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kt">float</span> <span class="n">valueToAdd</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kt">float</span> <span class="n">scale</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span> <span class="n">m</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">AddPluginCreator</span> <span class="o">:</span> <span class="k">public</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">IPluginCreator</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//这个函数会被onnx-tensorrt的一个叫做TRT_PluginV2的转换op调用，这个op会读取onnx模型的data数据将其反序列化到network中。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">nvinfer1</span><span class="o">::</span><span class="n">IPluginV2</span><span class="o">*</span> <span class="n">deserializePlugin</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">name</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span><span class="o">*</span> <span class="n">serialData</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">serialLength</span><span class="p">)</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="k">new</span> <span class="nf">AddPlugin</span><span class="p">(</span><span class="n">serialData</span><span class="p">,</span> <span class="n">serialLength</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="nf">getPluginName</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span><span class="k">return</span> <span class="s">&#34;AddPlugin&#34;</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="nf">getPluginVersion</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span><span class="k">return</span> <span class="s">&#34;0&#34;</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="nf">setPluginNamespace</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">szNamespace</span><span class="p">)</span> <span class="k">override</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="nf">getPluginNamespace</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span><span class="k">return</span> <span class="s">&#34;&#34;</span><span class="p">;}</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1">//这个是成员变量，也会作为getFieldNames成员函数的返回类型。		 PluginFieldCollection的主要作用是传递这个插件op所需要的权重和参数，在实际的engine推理过程中并不使用，而在parse中会用到(例如caffe2trt、onnx2trt)。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">PluginFieldCollection</span><span class="o">*</span> <span class="n">getFieldNames</span><span class="p">()</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">__FUNCTION__</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">nvinfer1</span><span class="o">::</span><span class="n">IPluginV2</span><span class="o">*</span> <span class="n">createPlugin</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">name</span><span class="p">,</span> <span class="k">const</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">PluginFieldCollection</span><span class="o">*</span> <span class="n">fc</span><span class="p">)</span> <span class="k">override</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">__FUNCTION__</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kt">float</span> <span class="n">valueToAdd</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">fc</span><span class="o">-&gt;</span><span class="n">nbFields</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">strcmp</span><span class="p">(</span><span class="n">fc</span><span class="o">-&gt;</span><span class="n">fields</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">name</span><span class="p">,</span> <span class="s">&#34;valueToAdd&#34;</span><span class="p">))</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">valueToAdd</span> <span class="o">=</span> <span class="o">*</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">fc</span><span class="o">-&gt;</span><span class="n">fields</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">data</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="k">new</span> <span class="nf">AddPlugin</span><span class="p">({</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kFLOAT</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">valueToAdd</span><span class="p">,</span> <span class="mi">1</span><span class="p">});</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>再看<code>AddPlugin.cu</code>中的算子实现：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;AddPlugin.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&#34;cuda_fp16.h&#34;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;chrono&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;thread&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="n">__global__</span> <span class="kt">void</span> <span class="n">AddValue</span><span class="p">(</span><span class="n">T</span> <span class="o">*</span><span class="n">pDst</span><span class="p">,</span> <span class="n">T</span> <span class="o">*</span><span class="n">pSrc</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">,</span> <span class="n">T</span> <span class="n">valueToAdd</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">pDst</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">pSrc</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">+</span> <span class="n">valueToAdd</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">AddPlugin</span><span class="o">::</span><span class="n">enqueue</span><span class="p">(</span><span class="kt">int</span> <span class="n">nBatch</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span> <span class="k">const</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="kt">void</span> <span class="o">**</span><span class="n">outputs</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">workspace</span><span class="p">,</span> <span class="n">cudaStream_t</span> <span class="n">stream</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">nBatch</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span><span class="p">.</span><span class="n">inputDim</span><span class="p">.</span><span class="n">nbDims</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">n</span> <span class="o">*=</span> <span class="n">m</span><span class="p">.</span><span class="n">inputDim</span><span class="p">.</span><span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">printf</span><span class="p">(</span><span class="s">&#34;n=%d, nBatch=%d</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">nBatch</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">dataType</span> <span class="o">==</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kFLOAT</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Running fp32 kernel&#34;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="mi">20</span><span class="n">ms</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">AddValue</span><span class="o">&lt;&lt;&lt;</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1023</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="o">&gt;&gt;&gt;</span><span class="p">((</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">.</span><span class="n">valueToAdd</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span> <span class="k">else</span> <span class="nf">if</span> <span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">dataType</span> <span class="o">==</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">kHALF</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Running fp16 kernel&#34;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="mi">10</span><span class="n">ms</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">AddValue</span><span class="o">&lt;&lt;&lt;</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1023</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="o">&gt;&gt;&gt;</span><span class="p">((</span><span class="n">__half</span> <span class="o">*</span><span class="p">)</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="n">__half</span> <span class="o">*</span><span class="p">)</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">__half</span><span class="p">)</span><span class="n">m</span><span class="p">.</span><span class="n">valueToAdd</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Running int8 kernel&#34;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="mi">0</span><span class="n">ms</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="kt">float</span> <span class="n">valueToAdd</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">valueToAdd</span> <span class="o">/</span> <span class="n">m</span><span class="p">.</span><span class="n">scale</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;valueToAdd (int8 scaled): &#34;</span> <span class="o">&lt;&lt;</span> <span class="n">valueToAdd</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;, &#34;</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="n">valueToAdd</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">AddValue</span><span class="o">&lt;&lt;&lt;</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1023</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="o">&gt;&gt;&gt;</span><span class="p">((</span><span class="kt">int8_t</span> <span class="o">*</span><span class="p">)</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="kt">int8_t</span> <span class="o">*</span><span class="p">)</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="kt">int8_t</span><span class="p">)</span><span class="n">valueToAdd</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="c1">//通过REGISTER_TENSORRT_PLUGIN注册plugin
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">REGISTER_TENSORRT_PLUGIN</span><span class="p">(</span><span class="n">AddPluginCreator</span><span class="p">);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h3 id="onnx-tensorrt中的plugin注册"><a href="#onnx-tensorrt中的plugin注册" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:onnx-tensorrt中的plugin注册" class="headings">onnx-tensorrt中的plugin注册</a></h3>
<p>同样地我们需要定义上述的<code>AddPlugin.h</code>和<code>AddPlugin.cu</code>,在<code>mian</code>函数中用<code>DEFINE_BUILTIN_OP_IMPORTER</code>注册算子：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">DEFINE_BUILTIN_OP_IMPORTER</span><span class="p">(</span><span class="n">AddPlugin</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">ASSERT</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">is_tensor</span><span class="p">(),</span> <span class="n">ErrorCode</span><span class="o">::</span><span class="n">kUNSUPPORTED_NODE</span><span class="p">);</span> 
</span></span><span class="line"><span class="cl">    <span class="p">...</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">pluginName</span> <span class="o">=</span> <span class="s">&#34;AddPlugin&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">pluginVersion</span> <span class="o">=</span> <span class="s">&#34;001&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 这个f保存这个op需要的权重和参数，从onnx模型中获取
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">nvinfer1</span><span class="o">::</span><span class="n">PluginField</span><span class="o">&gt;</span> <span class="n">f</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="s">&#34;in_channel&#34;</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">PluginFieldType</span><span class="o">::</span><span class="n">kINT32</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="s">&#34;weight&#34;</span><span class="p">,</span> <span class="n">kernel_weights</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">PluginFieldType</span><span class="o">::</span><span class="n">kFLOAT32</span><span class="p">,</span> <span class="n">kernel_weights</span><span class="p">.</span><span class="n">count</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="s">&#34;bias&#34;</span><span class="p">,</span> <span class="n">bias_weights</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">nvinfer1</span><span class="o">::</span><span class="n">PluginFieldType</span><span class="o">::</span><span class="n">kFLOAT32</span><span class="p">,</span> <span class="n">bias_weights</span><span class="p">.</span><span class="n">count</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// 这个从将plugin工厂中获取该插件，并且将权重和参数传递进去
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">nvinfer1</span><span class="o">::</span><span class="n">IPluginV2</span><span class="o">*</span> <span class="n">plugin</span> <span class="o">=</span> <span class="n">importPluginFromRegistry</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">pluginName</span><span class="p">,</span> <span class="n">pluginVersion</span><span class="p">,</span> <span class="n">node</span><span class="p">.</span><span class="n">name</span><span class="p">(),</span> <span class="n">f</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">RETURN_FIRST_OUTPUT</span><span class="p">(</span><span class="n">ctx</span><span class="o">-&gt;</span><span class="n">network</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">addPluginV2</span><span class="p">(</span><span class="n">tensors</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">tensors</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="o">*</span><span class="n">plugin</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h3 id="更多--工具和官方文档"><a href="#更多--工具和官方文档" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:更多--工具和官方文档" class="headings">更多&ndash;工具和官方文档</a></h3>
<p><a href="https://docs.nvidia.com/deeplearning/tensorrt/index.html" target="_blank" rel="noopener">TensorRT官方文档</a></p>
<p><code>onnx</code>到<code>trt</code>的众多转换工具(模型库)
<a href="https://github.com/onnx/onnx-tensorrt" target="_blank" rel="noopener">TensorRT Backend For ONNX</a></p>
<p><a href="https://github.com/NVIDIA-AI-IOT/torch2trt" target="_blank" rel="noopener">torch2trt</a></p>
<p><a href="https://github.com/grimoire/torch2trt_dynamic" target="_blank" rel="noopener">torch2trt_dynamic</a></p>
<p><a href="https://github.com/NVIDIA/TRTorch" target="_blank" rel="noopener">TRTorch</a></p>
<p>一些官方开源的小工具，帮助我们更好地调试和可视化：
<a href="https://github.com/NVIDIA/TensorRT/tree/master/tools" target="_blank" rel="noopener">TensorRTTools</a></p>
<h3 id="值得仔细研读的工程"><a href="#值得仔细研读的工程" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:值得仔细研读的工程" class="headings">值得仔细研读的工程</a></h3>
<p><a href="https://github.com/wang-xinyu/tensorrtx" target="_blank" rel="noopener">tensorrtx</a></p>
<p><a href="https://github.com/NVIDIA/trt-samples-for-hackathon-cn" target="_blank" rel="noopener">trt-samples-for-hackathon-cn</a></p>
            </div>

            


        </article>

        

        
    <div class="updated-badge-container">
        <span title="Updated @ 2021-05-28 10:09:12 CST" style="cursor:help">

<svg xmlns="http://www.w3.org/2000/svg" width="130" height="20" class="updated-badge"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#a)"><path class="updated-badge-left" d="M0 0h55v20H0z"/><path class="updated-badge-right" d="M55 0h75v20H55z"/><path fill="url(#b)" d="M0 0h130v20H0z"/></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2021-05-28</text><text x="915" y="140" textLength="650" transform="scale(.1)">2021-05-28</text></g></svg>
        </span></div>



        


        


        
    
    
        <div class="related-posts">
            <h2 class="related-title"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon related-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm144 276c0 6.6-5.4 12-12 12h-92v92c0 6.6-5.4 12-12 12h-56c-6.6 0-12-5.4-12-12v-92h-92c-6.6 0-12-5.4-12-12v-56c0-6.6 5.4-12 12-12h92v-92c0-6.6 5.4-12 12-12h56c6.6 0 12 5.4 12 12v92h92c6.6 0 12 5.4 12 12v56z"/></svg></h2>
            <ul class="related-list">
                
                    <li class="related-item">
                        <a href="/contents/attention/att_intro/" class="related-link">Transformer简介</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/contents/dl/deploy_torch_script/" class="related-link">利用TorchScript+libtorch部署c++模型</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/contents/gnn/gin/" class="related-link">GIN</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/contents/dl/plane_match/" class="related-link">基于图匹配的平面匹配算法</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/contents/attention/swim_transformer/" class="related-link">Swin Transformer总结</a>
                    </li>
                
            </ul>
        </div>
    



        


        
    <footer class="minimal-footer">
        
            <div class="post-tag"><a href="/tags/dl/" rel="tag" class="post-tag-link">#dl</a></div>
        
        
            <div class="post-category">
                <a href="/contents/" class="post-category-link active">时间线</a>
            </div>
        
        
    </footer>



        


        
    
        
        
    
    
    
    
        <ul class="post-nav">
            
            
                <li class="post-nav-next">
                    <a href="/contents/dl/deploy_torch_script/" rel="next">利用TorchScript+libtorch部署c++模型 &gt;</a>
                </li>
            
        </ul>
    



        


    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            
    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="site-info">2019–2023&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;JiaJie</div>

            
    
        <ul class="socials"><li class="socials-item">
                    <a href="https://applink.feishu.cn/client/chat/chatter/add_by_link?link_token=439md021-449c-4abb-95a7-40e75c699c2f" target="_blank" rel="external noopener" title="Lark"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M301.1 212c4.4 4.4 4.4 11.9 0 16.3l-9.7 9.7c-4.4 4.7-11.9 4.7-16.6 0l-10.5-10.5c-4.4-4.7-4.4-11.9 0-16.6l9.7-9.7c4.4-4.4 11.9-4.4 16.6 0l10.5 10.8zm-30.2-19.7c3-3 3-7.8 0-10.5-2.8-3-7.5-3-10.5 0-2.8 2.8-2.8 7.5 0 10.5 3.1 2.8 7.8 2.8 10.5 0zm-26 5.3c-3 2.8-3 7.5 0 10.2 2.8 3 7.5 3 10.5 0 2.8-2.8 2.8-7.5 0-10.2-3-3-7.7-3-10.5 0zm72.5-13.3c-19.9-14.4-33.8-43.2-11.9-68.1 21.6-24.9 40.7-17.2 59.8.8 11.9 11.3 29.3 24.9 17.2 48.2-12.5 23.5-45.1 33.2-65.1 19.1zm47.7-44.5c-8.9-10-23.3 6.9-15.5 16.1 7.4 9 32.1 2.4 15.5-16.1zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-66.2 42.6c2.5-16.1-20.2-16.6-25.2-25.7-13.6-24.1-27.7-36.8-54.5-30.4 11.6-8 23.5-6.1 23.5-6.1.3-6.4 0-13-9.4-24.9 3.9-12.5.3-22.4.3-22.4 15.5-8.6 26.8-24.4 29.1-43.2 3.6-31-18.8-59.2-49.8-62.8-22.1-2.5-43.7 7.7-54.3 25.7-23.2 40.1 1.4 70.9 22.4 81.4-14.4-1.4-34.3-11.9-40.1-34.3-6.6-25.7 2.8-49.8 8.9-61.4 0 0-4.4-5.8-8-8.9 0 0-13.8 0-24.6 5.3 11.9-15.2 25.2-14.4 25.2-14.4 0-6.4-.6-14.9-3.6-21.6-5.4-11-23.8-12.9-31.7 2.8.1-.2.3-.4.4-.5-5 11.9-1.1 55.9 16.9 87.2-2.5 1.4-9.1 6.1-13 10-21.6 9.7-56.2 60.3-56.2 60.3-28.2 10.8-77.2 50.9-70.6 79.7.3 3 1.4 5.5 3 7.5-2.8 2.2-5.5 5-8.3 8.3-11.9 13.8-5.3 35.2 17.7 24.4 15.8-7.2 29.6-20.2 36.3-30.4 0 0-5.5-5-16.3-4.4 27.7-6.6 34.3-9.4 46.2-9.1 8 3.9 8-34.3 8-34.3 0-14.7-2.2-31-11.1-41.5 12.5 12.2 29.1 32.7 28 60.6-.8 18.3-15.2 23-15.2 23-9.1 16.6-43.2 65.9-30.4 106 0 0-9.7-14.9-10.2-22.1-17.4 19.4-46.5 52.3-24.6 64.5 26.6 14.7 108.8-88.6 126.2-142.3 34.6-20.8 55.4-47.3 63.9-65 22 43.5 95.3 94.5 101.1 59z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://github.com/Wjiajie" target="_blank" rel="external noopener" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
                </li></ul>
    



            

<div class="container" role="main" itemscope itemtype="http://schema.org/Article">
    <div class="row">
        <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
           
            <article role="main" class="blog-post" itemprop="articleBody" id="content">
              
                
                
                
            </article>



        </div>
    </footer>


        </div>
        

        


    <script>
    if (typeof MathJax === 'undefined') {
        window.MathJax = {
            loader: {
                load: ['[tex]/mhchem']
            },
            
            tex: {
                inlineMath: {'[+]': [['$', '$']]},
                tags: 'ams',
                packages: {'[+]': ['mhchem']}
            }
        };
        (function() {
            const script = document.createElement('script');
            script.src = 'https:\/\/cdn.jsdelivr.net\/npm\/mathjax@3.1.2\/es5\/tex-mml-chtml.js';
            script.defer = true;
            document.head.appendChild(script);
        })();
    } else {
        MathJax.texReset();
        MathJax.typeset();
    }
</script>




    <script src="https://cdn.jsdelivr.net/npm/mermaid@8.8.3/dist/mermaid.min.js"></script>
<script>
    const mermaidConfig = {
        startOnLoad: true,
        flowchart: {
            useMaxWidth: false,
            htmlLabels: true
        },
        theme: 'default'
    };
    mermaid.initialize(mermaidConfig);
</script>





    <script src="/js/medium-zoom.min.js"></script>

<script>
    mediumZoom(document.querySelectorAll('div.post-body img'), {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module" defer></script>



    
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    




    </body>
</html>
