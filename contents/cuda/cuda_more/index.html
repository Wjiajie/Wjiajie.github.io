<!DOCTYPE html>
<html lang="zh-CN">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.119.0"><meta name="theme-color" content="#fff" />
    <meta name="color-scheme" content="light dark">

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>《GPU并行计算与CUDA编程》学习笔记 | W</title>

    <link rel="stylesheet" href="/css/meme.min.96e347d523b813536fdc3421352e9e644b8047878d88cce43c155eb8d960b21f.css"/>

    
    
        
            <script src="/js/meme.min.fc822ef956a26b79d064473732b590e06e47caa64a3d17a46efb5223daf463e4.js"></script>

        
    

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" media="print" onload="this.media='all'" />
        <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" /></noscript>

    <meta name="author" content="JiaJie" /><meta name="description" content="本文主要记录在学习《GPU并行计算与CUDA编程》过程中的知识要点，并且把跑过的代码统一放在cmake工程里面。
关于cuda更具体的介绍，一个博客专题介绍的很好： CUDA从入门到入门
对应的代码在： https://github.com/Tony-Tan/CUDA_Freshman
……" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="W" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="W" />
    <meta name="msapplication-starturl" content="../../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
        <link rel="canonical" href="https://wjiajie.github.io/contents/cuda/cuda_more/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2020-09-29T15:43:08+08:00",
        "dateModified": "2021-05-14T09:09:40+08:00",
        "url": "https://wjiajie.github.io/contents/cuda/cuda_more/",
        "headline": "《GPU并行计算与CUDA编程》学习笔记",
        "description": "本文主要记录在学习《GPU并行计算与CUDA编程》过程中的知识要点，并且把跑过的代码统一放在cmake工程里面。\n关于cuda更具体的介绍，一个博客专题介绍的很好： CUDA从入门到入门\n对应的代码在： https://github.com/Tony-Tan/CUDA_Freshman\n……",
        "inLanguage" : "zh-CN",
        "articleSection": "contents",
        "wordCount":  8305 ,
        "image": ["https://i.loli.net/2019/05/25/5ce8acf85ef8e11960.png","https://i.loli.net/2021/05/11/IQZ6fbErAcvPsUS.png","https://i.loli.net/2021/05/13/ayOr2e9t1S3dNFG.png","https://i.loli.net/2021/05/14/6RAO7wzS9Be3KCb.png","https://i.loli.net/2021/05/14/LQvKJuzGRUbHEd3.png","https://i.loli.net/2021/05/14/QVtoEiM7wzLUu2S.png","https://i.loli.net/2021/05/14/FjgxSJ6asMTUzOe.png","https://i.loli.net/2021/05/14/hUylfbutnIpGAYg.jpg","https://i.loli.net/2021/05/12/wmG2ODiNkVxZKgs.png","https://i.loli.net/2021/05/14/q1TX43pwShjBvk8.png","https://i.loli.net/2021/05/14/7w1V3ZmArQFfGRt.png"],
        "author": {
            "@type": "Person",
            "description": "Viva La Vida",
            "email": "jiajiewu233@gamil.com",
            "image": "https://s2.loli.net/2023/02/25/bTD9PrGNyC8kRi5.png",
            "url": "https://www.jiajiewu.top/",
            "name": "JiaJie"
        },
        "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)",
        "publisher": {
            "@type": "Organization",
            "name": "W",
            "logo": {
                "@type": "ImageObject",
                "url": "https://wjiajie.github.io/icons/apple-touch-icon.png"
            },
            "url": "https://wjiajie.github.io/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://wjiajie.github.io/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary_large_image" />



    



<meta property="og:title" content="《GPU并行计算与CUDA编程》学习笔记" />
<meta property="og:description" content="本文主要记录在学习《GPU并行计算与CUDA编程》过程中的知识要点，并且把跑过的代码统一放在cmake工程里面。
关于cuda更具体的介绍，一个博客专题介绍的很好： CUDA从入门到入门
对应的代码在： https://github.com/Tony-Tan/CUDA_Freshman
……" />
<meta property="og:url" content="https://wjiajie.github.io/contents/cuda/cuda_more/" />
<meta property="og:site_name" content="W" />
<meta property="og:locale" content="zh" /><meta property="og:image" content="https://i.loli.net/2019/05/25/5ce8acf85ef8e11960.png" />
<meta property="og:type" content="article" />
    <meta property="article:published_time" content="2020-09-29T15:43:08&#43;08:00" />
    <meta property="article:modified_time" content="2021-05-14T09:09:40&#43;08:00" />
    
    <meta property="article:section" content="contents" />


        <link rel="preconnect" href="https://www.google-analytics.com" crossorigin />

        


    
    <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', '');
    </script>




    
    

    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>



<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@700&amp;text=reuixiy&amp;display=swap" media="print" onload="this.media='all'" />
<noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@700&amp;text=reuixiy&amp;display=swap" /></noscript>





</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="/" class="brand">W</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        
            
        
        
        
        
            
                <li class="menu-item"><a href="/contents/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon folder"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg><span class="menu-item-name">Contents</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/contents/photos/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" class="icon eye"><path d="M288 144a110.94 110.94 0 0 0-31.24 5 55.4 55.4 0 0 1 7.24 27 56 56 0 0 1-56 56 55.4 55.4 0 0 1-27-7.24A111.71 111.71 0 1 0 288 144zm284.52 97.4C518.29 135.59 410.93 64 288 64S57.68 135.64 3.48 241.41a32.35 32.35 0 0 0 0 29.19C57.71 376.41 165.07 448 288 448s230.32-71.64 284.52-177.41a32.35 32.35 0 0 0 0-29.19zM288 400c-98.65 0-189.09-55-237.93-144C98.91 167 189.34 112 288 112s189.09 55 237.93 144C477.1 345 386.66 400 288 400z"/></svg><span class="menu-item-name">Photos</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/about/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon plus-circle"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm144 276c0 6.6-5.4 12-12 12h-92v92c0 6.6-5.4 12-12 12h-56c-6.6 0-12-5.4-12-12v-92h-92c-6.6 0-12-5.4-12-12v-56c0-6.6 5.4-12 12-12h92v-92c0-6.6 5.4-12 12-12h56c6.6 0 12 5.4 12 12v92h92c6.6 0 12 5.4 12 12v56z"/></svg><span class="menu-item-name">About</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5l48.8-97.5a18 18 0 0128 0l48.8 97.5 103.4 -34.5a18 18 0 0119.8 19.8l-34.5 103.4l97.5 48.8a18 18 0 010 28l-97.5 48.8 34.5 103.4a18 18 0 01-19.8 19.8l-103.4-34.5-48.8 97.5a18 18 0 01-28 0l-48.8-97.5l-103.4 34.5a18 18 0 01-19.8-19.8l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8-34.5-103.4a18 18 0 0119.8-19.8zM256 128a128 128 0 10.01 0M256 160a96 96 0 10.01 0"/></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412a256 256 0 10154-407a11.5 11.5 0 00-5 20a201.5 201.5 0 01-134 374a11.5 11.5 0 00-15 13"/></svg></a>
                        </li>
                    
                
            
        
            
                
            
        
            
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            
    <input type="checkbox" id="nav-toggle" aria-hidden="true" />
    <label for="nav-toggle" class="nav-toggle"></label>
    <label for="nav-toggle" class="nav-curtain"></label>


        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-align="justify" data-type="contents" data-toc-num="true">

            <h1 class="post-title p-name">《GPU并行计算与CUDA编程》学习笔记</h1>

            

            
                
            

            
                

<div class="post-meta">
    
        
        <time datetime="2020-09-29T15:43:08&#43;08:00" class="post-meta-item published dt-published"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6 0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48c26.5 0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"/></svg>&nbsp;2020.9.29</time>
    
    
        
        <time datetime="2021-05-14T09:09:40&#43;08:00" class="post-meta-item modified dt-updated"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M400 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H48C21.49 64 0 85.49 0 112v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 400H54a6 6 0 0 1-6-6V160h352v298a6 6 0 0 1-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"/></svg>&nbsp;2021.5.14</time>
    
    
    
        
        
        
            
        
    
    
        
        <span class="post-meta-item wordcount"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;8305</span>
    
    
        
        <span class="post-meta-item reading-time"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;17&nbsp;分钟</span>
    
    
    
</div>

            

            <nav class="contents">
  <h2 id="contents" class="contents-title">目录</h2><ol class="toc">
    <li><a id="contents:基础" href="#基础">基础</a></li>
    <li><a id="contents:要点记录" href="#要点记录">要点记录</a>
      <ol>
        <li><a id="contents:gpu的硬件模式" href="#gpu的硬件模式">gpu的硬件模式</a></li>
        <li><a id="contents:cuda中的标识符" href="#cuda中的标识符">cuda中的标识符</a></li>
        <li><a id="contents:gpu-的内存结构" href="#gpu-的内存结构">gpu 的内存结构</a></li>
        <li><a id="contents:cuda编程原则" href="#cuda编程原则">cuda编程原则</a></li>
      </ol>
    </li>
    <li><a id="contents:练习代码" href="#练习代码">练习代码</a></li>
  </ol>
</nav><div class="post-body e-content">
                <p>本文主要记录在学习<a href="http://www.dataguru.cn/article-10022-1.html" target="_blank" rel="noopener"><strong>《GPU并行计算与CUDA编程》</strong></a>过程中的知识要点，并且把跑过的代码统一放在cmake工程里面。</p>
<p>关于cuda更具体的介绍，一个博客专题介绍的很好：
<a href="https://face2ai.com/categories/CUDA/" target="_blank" rel="noopener">CUDA从入门到入门</a></p>
<p>对应的代码在： <a href="https://github.com/Tony-Tan/CUDA_Freshman" target="_blank" rel="noopener">https://github.com/Tony-Tan/CUDA_Freshman</a></p>
<img src="https://i.loli.net/2019/05/25/5ce8acf85ef8e11960.png" width = "100%"  div align = center />
<h2 id="基础"><a href="#基础" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:基础" class="headings">基础</a></h2>
<p>关于 <em>cuda</em> 的基础知识参考之前的文章：</p>
<ul>
<li><a href="https://jiajiewu.gitee.io/post/tech/cuda/cuda-practice1/" target="_blank" rel="noopener">cuda学习笔记1</a></li>
<li><a href="https://jiajiewu.gitee.io/post/tech/cuda/cuda-practice2/" target="_blank" rel="noopener">cuda学习笔记2</a></li>
<li><a href="https://jiajiewu.gitee.io/post/tech/cuda/cuda-practice3/" target="_blank" rel="noopener">cuda学习笔记3</a></li>
<li><a href="https://jiajiewu.gitee.io/post/tech/cuda/cuda-practice4/" target="_blank" rel="noopener">cuda学习笔记4</a></li>
<li><a href="https://jiajiewu.gitee.io/post/tech/cuda/cuda-practice5/" target="_blank" rel="noopener">cuda学习笔记5</a></li>
</ul>
<p>最详细最新的内容，还看官网：<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" target="_blank" rel="noopener">CUDA C++ Programming Guide</a>。</p>
<p>在CMake编译cuda程序，和编译一般的cpp程序几乎相同：</p>
<p>CMakeLists.txt编写如下：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-txt" data-lang="txt"><span class="line"><span class="cl">cmake_minimum_required(VERSION 3.8)
</span></span><span class="line"><span class="cl">project(CUDA_MAT_MUL LANGUAGES CXX CUDA)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">aux_source_directory(cuda_src CUDA_SRC_LIST)
</span></span><span class="line"><span class="cl">aux_source_directory(cuda_head CUDA_INCLUDE_LIST)
</span></span><span class="line"><span class="cl">include_directories(cuda_head)
</span></span><span class="line"><span class="cl">add_library(cudaPractice ${CUDA_SRC_LIST} ${CUDA_INCLUDE_LIST})
</span></span><span class="line"><span class="cl">target_compile_features(cudaPractice PUBLIC cxx_std_11)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">#opencv
</span></span><span class="line"><span class="cl">find_package(OpenCV 3.4.3 REQUIRED)
</span></span><span class="line"><span class="cl">include_directories( ${OpenCV_INCLUDE_DIRS} )
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">add_executable(main main.cc)
</span></span><span class="line"><span class="cl">target_link_libraries(main cudaPractice)
</span></span><span class="line"><span class="cl">target_link_libraries(main ${OpenCV_LIBS})
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>目录结构如下所示：</p>
<p><img src="https://i.loli.net/2021/05/11/IQZ6fbErAcvPsUS.png" alt="Screenshot from 2021-05-11 20-00-16.png"><span class="caption">◎ 目录结构</span></p>
<p><code>add_library</code>把cuda的源文件和头文件打包到静态库里面，然后<code>target_compile_features</code>和<code>target_link_libraries</code>调用打包的静态库。</p>
<h2 id="要点记录"><a href="#要点记录" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:要点记录" class="headings">要点记录</a></h2>
<p><img src="https://i.loli.net/2021/05/13/ayOr2e9t1S3dNFG.png" alt="Screenshot from 2021-05-13 11-20-54.png"><span class="caption">◎ cpu和gpu的结构比较</span></p>
<h3 id="gpu的硬件模式"><a href="#gpu的硬件模式" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:gpu的硬件模式" class="headings">gpu的硬件模式</a></h3>
<ul>
<li>GPU，SM(流处理器)，Kernel(核)，thread block(线程块)，线程</li>
</ul>
<p><img src="https://i.loli.net/2021/05/14/6RAO7wzS9Be3KCb.png" alt="Screenshot from 2021-05-14 11-15-18.png"><span class="caption">◎ 流处理器</span></p>
<p><img src="https://i.loli.net/2021/05/14/LQvKJuzGRUbHEd3.png" alt="Screenshot from 2021-05-14 11-15-26.png"><span class="caption">◎ 核，线程块和线程</span></p>
<ul>
<li>CPU的<code>ALU</code>, <code>Cache</code>和<code>Control</code>单元的特点</li>
</ul>
<blockquote>
<p>ALU：CPU有强大的ALU（算术运算单元）,它可以在很少的时钟周期内完成算术计算。
当今的CPU可以达到64bit 双精度。执行双精度浮点源算的加法和乘法只需要1～3个时钟周期。
CPU的时钟周期的频率是非常高的，达到1.532～3gigahertz(千兆HZ, 10的9次方).
Cache：大的缓存也可以降低延时。保存很多的数据放在缓存里面，当需要访问的这些数据，只要在之前访问过的，如今直接在缓存里面取即可。
Control：复杂的逻辑控制单元。
当程序含有多个分支的时候，它通过提供分支预测的能力来降低延时。
数据转发。 当一些指令依赖前面的指令结果时，数据转发的逻辑控制单元决定这些指令在pipeline中的位置并且尽可能快的转发一个指令的结果给后续的指令。这些动作需要很多的对比电路单元和转发电路单元。</p>
</blockquote>
<ul>
<li>GPU的<code>ALU</code>, <code>Cache</code>和<code>Control</code>单元的特点</li>
</ul>
<blockquote>
<p>ALU，Cache：GPU的特点是有很多的ALU和很少的cache. 缓存的目的不是保存后面需要访问的数据的，这点和CPU不同，而是为thread提高服务的。如果有很多线程需要访问同一个相同的数据，缓存会合并这些访问，然后再去访问dram（因为需要访问的数据保存在dram中而不是cache里面），获取数据后cache会转发这个数据给对应的线程，这个时候是数据转发的角色。但是由于需要访问dram，自然会带来延时的问题。
Control：控制单元（左边黄色区域块）可以把多个的访问合并成少的访问。
GPU的虽然有dram延时，却有非常多的ALU和非常多的thread. 为了平衡内存延时的问题，我们可以中充分利用多的ALU的特性达到一个非常大的吞吐量的效果。尽可能多的分配多的Threads.通常来看GPU ALU会有非常重的pipeline就是因为这样。
CPU擅长逻辑控制，串行的运算。和通用类型数据运算不同，GPU擅长的是大规模并发计算，这也正是密码破解等所需要的。所以GPU除了图像处理，也越来越多的参与到计算当中来。</p>
</blockquote>
<ul>
<li>cuda常用库</li>
</ul>
<blockquote>
<p>CUDA函数库
CUDA提供了几个较为成熟的高效函数库,程序员可以 直接调用这些库函数进行计算,因而大大简化了程序员 的工作量。其中最常用的包括:
CUFFT （利用CUDA进行傅里叶变换的函数库 ）
CUBLAS （利用CUDA进行加速版本的完 整标准矩阵与向量的运算库 ）
CUDPP （常用的并行操作函数库）
CUDNN （利用CUDA进行深度卷积神经网络，深度学习常用）
全部库：https://developer.nvidia.com/gpu-accelerated-libraries</p>
</blockquote>
<h3 id="cuda中的标识符"><a href="#cuda中的标识符" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:cuda中的标识符" class="headings">cuda中的标识符</a></h3>
<ol>
<li><code>__global__</code>, <code>__device__</code>用来标识某个函数是设备代码而不是主机代码，而<code>__host__</code>表示主机代码(可以不写)。 主机/设备上的变量，在设备/主机上只可以访问而不能修改，不能在主机代码中用主机指针访问设备内存，反过来也一样，不能用设备指针访问主机内存。</li>
</ol>
<p><img src="https://i.loli.net/2021/05/14/QVtoEiM7wzLUu2S.png" alt="Screenshot from 2021-05-14 11-53-00.png"><span class="caption">◎ global, device, host</span></p>
<ol start="2">
<li>
<p>cuda中threadIdx、blockIdx、blockDim和gridDim的使用</p>
<p>threadIdx是一个uint3类型，表示一个线程的索引。调用方法：(a.x, a.y, a.z)</p>
<p>blockIdx是一个uint3类型，表示一个线程块的索引，一个线程块中通常有多个线程。</p>
<p>blockDim是一个dim3类型，表示线程块的大小。</p>
<p>gridDim是一个dim3类型，表示网格的大小，一个网格中通常有多个线程块。</p>
</li>
</ol>
<p>一维线程的使用：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">add_kernel</span><span class="p">(</span><span class="kt">double</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">c</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//block id
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="n">c</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>	
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">err1</span> <span class="o">=</span> <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="n">err2</span> <span class="o">=</span> <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="n">err3</span> <span class="o">=</span> <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_c</span><span class="p">,</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//表示 N 个block， 每个block分配 1个 thread
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">add_kernel</span> <span class="o">&lt;&lt;</span> <span class="o">&lt;</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span> <span class="o">&gt;&gt;</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">);</span><span class="c1">////在GPU上相加操作
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="c1">////用完设备指针要释放
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_a</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_b</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_c</span><span class="p">);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>二维block的使用：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">kernel</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">char</span> <span class="o">*</span><span class="n">ptr</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="kt">int</span> <span class="n">y</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="kt">int</span> <span class="n">offset</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//...
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="kt">unsigned</span> <span class="kt">char</span> <span class="o">*</span><span class="n">dev_bitmap</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">HANDLE_ERROR</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_bitmap</span><span class="p">,</span> <span class="n">bitmap</span><span class="p">.</span><span class="n">image_size</span><span class="p">()));</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">dim3</span> <span class="nf">grid</span><span class="p">(</span><span class="n">DIM1</span><span class="p">,</span> <span class="n">DIM2</span><span class="p">);</span> <span class="c1">////实际上是DIM1*DIM2*1的三维线程格
</span></span></span><span class="line"><span class="cl"><span class="c1">//三维grid, 1个thread
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">kernel</span> <span class="o">&lt;&lt;</span> <span class="o">&lt;</span><span class="n">grid</span><span class="p">,</span> <span class="mi">1</span> <span class="o">&gt;&gt;</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">dev_bitmap</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">HANDLE_ERROR</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_bitmap</span><span class="p">));</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>更多自由搭配：(1/2/3维度block)*(1/2/3维度thread):</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="c1">//thread 1D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testThread1</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//thread 2D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testThread2</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//thread 3D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testThread3</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block 1D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlock1</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block 2D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlock2</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block 3D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlock3</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block-thread 1D-1D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlockThread1</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block-thread 1D-2D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlockThread2</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">threadId_2D</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadId_2D</span><span class="o">+</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block-thread 1D-3D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlockThread3</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">threadId_3D</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadId_3D</span> <span class="o">+</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block-thread 2D-1D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlockThread4</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">blockId_2D</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockId_2D</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block-thread 3D-1D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlockThread5</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">blockId_3D</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockId_3D</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block-thread 2D-2D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlockThread6</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">threadId_2D</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">blockId_2D</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadId_2D</span> <span class="o">+</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">blockId_2D</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block-thread 2D-3D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlockThread7</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">threadId_3D</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">blockId_2D</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadId_3D</span> <span class="o">+</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="n">blockId_2D</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block-thread 3D-2D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlockThread8</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">threadId_2D</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">blockId_3D</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadId_2D</span> <span class="o">+</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">blockId_3D</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//block-thread 3D-3D
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">testBlockThread9</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">threadId_3D</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">blockId_3D</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadId_3D</span> <span class="o">+</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="n">blockId_3D</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl">	<span class="c1">//testThread1&lt;&lt;&lt;1, size&gt;&gt;&gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s;s.x = size/5;s.y = 5;s.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testThread2 &lt;&lt;&lt;1,s&gt;&gt;&gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s; s.x = size / 10; s.y = 5; s.z = 2;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testThread3&lt;&lt;&lt;1, s &gt;&gt;&gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//testBlock1&lt;&lt;&lt;size,1 &gt;&gt;&gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s; s.x = size / 5; s.y = 5; s.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testBlock2&lt;&lt;&lt;s, 1 &gt;&gt;&gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s; s.x = size / 10; s.y = 5; s.z = 2;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testBlock3&lt;&lt;&lt;s, 1 &gt;&gt;&gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//testBlockThread1&lt;&lt;&lt;size/10, 10&gt;&gt;&gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s1; s1.x = size / 100; s1.y = 1; s1.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//uint3 s2; s2.x = 10; s2.y = 10; s2.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testBlockThread2 &lt;&lt; &lt;s1, s2 &gt;&gt; &gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s1; s1.x = size / 100; s1.y = 1; s1.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//uint3 s2; s2.x = 10; s2.y = 5; s2.z = 2;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testBlockThread3 &lt;&lt; &lt;s1, s2 &gt;&gt; &gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s1; s1.x = 10; s1.y = 10; s1.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//uint3 s2; s2.x = size / 100; s2.y = 1; s2.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testBlockThread4 &lt;&lt; &lt;s1, s2 &gt;&gt; &gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s1; s1.x = 10; s1.y = 5; s1.z = 2;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//uint3 s2; s2.x = size / 100; s2.y = 1; s2.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testBlockThread5 &lt;&lt; &lt;s1, s2 &gt;&gt; &gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s1; s1.x = size / 100; s1.y = 10; s1.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//uint3 s2; s2.x = 5; s2.y = 2; s2.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testBlockThread6 &lt;&lt; &lt;s1, s2 &gt;&gt; &gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s1; s1.x = size / 100; s1.y = 5; s1.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//uint3 s2; s2.x = 5; s2.y = 2; s2.z = 2;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testBlockThread7 &lt;&lt; &lt;s1, s2 &gt;&gt; &gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">//uint3 s1; s1.x = 5; s1.y = 2; s1.z = 2;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//uint3 s2; s2.x = size / 100; s2.y = 5; s2.z = 1;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">//testBlockThread8 &lt;&lt;&lt;s1, s2 &gt;&gt;&gt;(dev_c, dev_a, dev_b);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="n">uint3</span> <span class="n">s1</span><span class="p">;</span> <span class="n">s1</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="n">s1</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">s1</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">uint3</span> <span class="n">s2</span><span class="p">;</span> <span class="n">s2</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">size</span> <span class="o">/</span> <span class="mi">200</span><span class="p">;</span> <span class="n">s2</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="n">s2</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">testBlockThread9</span><span class="o">&lt;&lt;&lt;</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span> <span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dev_c</span><span class="p">,</span> <span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1">//或者：
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">dim3</span>    <span class="nf">blocks</span><span class="p">(</span><span class="n">DIM</span><span class="o">/</span><span class="mi">16</span><span class="p">,</span><span class="n">DIM</span><span class="o">/</span><span class="mi">16</span><span class="err">，</span><span class="mi">1</span><span class="p">);</span> <span class="c1">////二维线程块
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">dim3</span>    <span class="nf">threads</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span> <span class="c1">////二维线程
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">func_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="n">threads</span><span class="o">&gt;&gt;&gt;</span><span class="err">（参数）；</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>注意的是 <code>blockDim.x</code>和<code> gridDim.x</code>确实有一个物理上的最大值，但在使用时的大小是由在代码中的设定决定的，比如下面的：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">add_kernel</span><span class="p">(</span><span class="kt">double</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">c</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="n">c</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">		<span class="n">tid</span> <span class="o">+=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"> 	<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">add_kernel</span> <span class="o">&lt;&lt;</span> <span class="o">&lt;</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span> <span class="o">&gt;&gt;</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">);</span><span class="c1">////在GPU上相加操作
</span></span></span></code></pre></td></tr></table></div>
</div>
</div><p><code>blockDim.x</code>和<code>gridDim.x</code>都为128， 128，确实这样是合理的，它让我们可以固定具体使用多少的<code>thread</code>，而不因为数据扩增而导致出现异常。同理地，合理的设置使得<code>blockDim.x</code>和<code>gridDim.x</code>逼近gpu的计算上限，可以充分利用gpu的计算能力。</p>
<ol start="3">
<li>在设备代码上定义结构体(类)</li>
</ol>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">cuComplex</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="kt">float</span> <span class="n">r</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="kt">float</span> <span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">__device__</span> <span class="nf">cuComplex</span><span class="p">(</span><span class="kt">float</span> <span class="n">a</span><span class="p">,</span> <span class="kt">float</span> <span class="n">b</span><span class="p">)</span> <span class="o">:</span><span class="n">r</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">i</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">	<span class="n">__device__</span> <span class="kt">float</span> <span class="nf">magnitude2</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="n">r</span><span class="o">*</span><span class="n">r</span> <span class="o">+</span> <span class="n">i</span><span class="o">*</span><span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span> <span class="c1">////返回复数的模的平方
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">__device__</span> <span class="n">cuComplex</span> <span class="k">operator</span><span class="o">*</span><span class="p">(</span><span class="k">const</span> <span class="n">cuComplex</span><span class="o">&amp;</span> <span class="n">a</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="nf">cuComplex</span><span class="p">(</span><span class="n">r</span><span class="o">*</span><span class="n">a</span><span class="p">.</span><span class="n">r</span> <span class="o">-</span> <span class="n">i</span><span class="o">*</span><span class="n">a</span><span class="p">.</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">*</span><span class="n">a</span><span class="p">.</span><span class="n">r</span> <span class="o">+</span> <span class="n">r</span><span class="o">*</span><span class="n">a</span><span class="p">.</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="n">__device__</span> <span class="n">cuComplex</span> <span class="k">operator</span><span class="o">+</span><span class="p">(</span><span class="k">const</span> <span class="n">cuComplex</span><span class="o">&amp;</span> <span class="n">a</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="nf">cuComplex</span><span class="p">(</span><span class="n">r</span> <span class="o">+</span> <span class="n">a</span><span class="p">.</span><span class="n">r</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="n">a</span><span class="p">.</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>可以看到，和常用的<code>C++</code>代码，区别也只在于函数定义是否有<code>__device__</code>标识符。</p>
<h3 id="gpu-的内存结构"><a href="#gpu-的内存结构" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:gpu-的内存结构" class="headings">gpu 的内存结构</a></h3>
<p><a href="https://zhuanlan.zhihu.com/p/158548901" target="_blank" rel="noopener">GPU编程3--GPU内存深入了解</a>这篇文章讲的很清楚。</p>
<p><img src="https://i.loli.net/2021/05/14/FjgxSJ6asMTUzOe.png" alt="20170808184924090.png"></p>
<p><img src="https://i.loli.net/2021/05/14/hUylfbutnIpGAYg.jpg" alt="v2-f1441ce6bd850e284a1637ba7ed51b60_r.jpg"></p>
<p>cuda中有寄存器内存，局部内存，共享内存，常量内存，纹理内存，全局内存。寄存器内存用于定义线程专属私有变量。当私有变量申请大小溢出时，自动转为局部内存。当在核函数里面申请局部数组时，自动称为局部内存。</p>
<ol>
<li>共享内存</li>
</ol>
<blockquote>
<p>共享内存（shared memory，SMEM）是GPU的一个关键部分，物理层面，每个SM都有一个小的内存池，这个线程池被次SM上执行的线程块中的所有线程所共享。共享内存使同一个线程块中可以相互协同，便于片上的内存可以被最大化的利用，降低回到全局内存读取的延迟。
共享内存是被我们用代码控制的，这也是是他称为我们手中最灵活的优化武器。
一级缓存，二级缓存，共享内存，以及只读和常量缓存，他们的关系如下图：</p>
</blockquote>
<p><img src="https://i.loli.net/2021/05/12/wmG2ODiNkVxZKgs.png" alt="5-1.png"><span class="caption">◎ 一级缓存，二级缓存，共享内存，以及只读和常量缓存</span></p>
<p>可以看到， 共享内存(SMEM)， 一级缓存， 只读缓存和常量缓存更接近SM计算核心，有更低的访问延迟和传输带宽。</p>
<blockquote>
<p>将线程块分解为线程的目的，除了物理设备上线程块最大数目的限制，还有一个原因是 CUDA C支持共享内存。对于GPU上的每一个线程块，编译器都为该共享变量创建一个副本，而线程块中的每一个线程共享这块内存。由于共享内存驻留在物理GPU上而不是GPU之外的系统内存中，访问共享内存的延迟要远低于访问普通内缓存区的延迟。</p>
</blockquote>
<p>利用共享内存实现内积(dot):</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">dot</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">c</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="n">__shared__</span> <span class="kt">float</span> <span class="n">cache</span><span class="p">[</span><span class="n">threadsPerBlock</span><span class="p">];</span>  <span class="c1">////共享内存缓存区（驻留在物理GPU上），编译器为每一个线程块生成一个共享变量的副本。同一线程块中的每个线程共享这块内存。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span> <span class="c1">////索引偏置
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="kt">int</span> <span class="n">cacheIndex</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span> <span class="c1">////由于每一个线程块都具有一个共享内存的副本，故共享内存的索引就是该线程块上的线程索引。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">	<span class="kt">float</span>   <span class="n">temp</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="k">while</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="n">temp</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">		<span class="n">tid</span> <span class="o">+=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c1">// set the cache values
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">cache</span><span class="p">[</span><span class="n">cacheIndex</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">;</span> <span class="c1">////每个线程处理的数据，相加放在对应的共享内存区域中。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">	<span class="c1">// synchronize threads in this block
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">__syncthreads</span><span class="p">();</span>  <span class="c1">////线程同步，当所有的线程都执行完以上操作时，才能继续执行下一步。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">	<span class="c1">// for reductions, threadsPerBlock must be a power of 2
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">// because of the following code
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">////归约，将共享内存区域每一个储存的值相加起来，由于规约每次迭代数量减半，要求 threadsPerBlock 是2 的指数倍。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="k">while</span> <span class="p">(</span><span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="p">(</span><span class="n">cacheIndex</span> <span class="o">&lt;</span> <span class="n">i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">			<span class="n">cache</span><span class="p">[</span><span class="n">cacheIndex</span><span class="p">]</span> <span class="o">+=</span> <span class="n">cache</span><span class="p">[</span><span class="n">cacheIndex</span> <span class="o">+</span> <span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">		<span class="n">__syncthreads</span><span class="p">();</span> <span class="c1">////线程同步。同样地，执行下一次规约迭代前，必须确保所有线程都已经执行完上面相加的操作。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>		<span class="n">i</span> <span class="o">/=</span> <span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="p">(</span><span class="n">cacheIndex</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">c</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>  <span class="c1">////把一个线程块中的最后计算得到的相加值返还给全局变量。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>若申请<code>blocksPerGrid</code>个block, 则会在gpu上创建<code>blocksPerGrid</code>个共享内存副本。</p>
<p>共享内存和<code>block</code>同生命周期。</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">dot</span> <span class="o">&lt;&lt;</span> <span class="o">&lt;</span><span class="n">blocksPerGrid</span><span class="p">,</span> <span class="n">threadsPerBlock</span> <span class="o">&gt;&gt;</span> <span class="o">&gt;</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="n">dev_partial_c</span><span class="p">);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><ol start="2">
<li>常量内存</li>
</ol>
<blockquote>
<p>常量内存用于保存在核函数执行期间不会发生变化的数据，由于GPU的性能瓶颈通常不在于芯片的数学吞吐能力，而在于芯片的内存带宽，合理利用常量内存能有效减小内存的带宽的消耗。常量内存存在于核函数之外，在kernel函数外声明，即常量内存存在于内存中，并不在片上，常量内容的访问速度也是很快的，这是因为每个SM都有专用的常量内存缓存，会把片外的常量读取到缓存中；对所有的核函数都可见，在Host端进行初始化后，核函数不能再修改。</p>
</blockquote>
<p>写法：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">__constant__</span> <span class="n">Sphere</span> <span class="n">s</span><span class="p">[</span><span class="n">num</span><span class="p">]</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>对于常量内存，不需要再用 cudaMalloc() 或者 cudaFree() 来申请或释放内存空间，编译器会自动为这个数组提交一个固定的大小。</p>
<p><code>cudaMemcpy()</code> 会将主机内存复制到全局内存，而<code>cudaMemcpyToSymbol()</code> 会将主机内存复制到常量内存。</p>
<p>常量内存为什么有效：</p>
<ol>
<li>
<p>对常量内存的单次操作可以广播到其他临近线程，范围为半个线程束（Wrap）。</p>
</li>
<li>
<p>常量内存的数据将缓存起来，因此对相同地址的连续读操作不会产生额外的内存通信量。</p>
</li>
</ol>
<blockquote>
<p>在CUDA架构中，线程束是指包含32个线程的集合，这个线程集合被“编织”在一起并且以“步调一致”的形式执行，在程序的每一行，线程束中的每个线程都在不同的数据中执行相同的操作。当这半个线程束读取常量内存相同地址时，才可以大幅度提升性能，否则，这半个线程束的请求会被串行化，在这个情况下性能反而会降低。</p>
</blockquote>
<blockquote>
<p>常量内存有两个特性，一个是高速缓存，另一个是它支持将单个值广播到线程束中的每个线程。但要注意的是，对于那些数据不太集中或者数据重用率不高的内存访问，尽量不要使用常量内存。</p>
</blockquote>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="cp">#define SPHERES 20
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="n">__constant__</span> <span class="n">Sphere</span> <span class="n">s</span><span class="p">[</span><span class="n">SPHERES</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="c1">// allocate temp memory, initialize it, copy to constant
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">// memory on the GPU, then free our temp memory
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">Sphere</span> <span class="o">*</span><span class="n">temp_s</span> <span class="o">=</span> <span class="p">(</span><span class="n">Sphere</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="n">Sphere</span><span class="p">)</span> <span class="o">*</span> <span class="n">SPHERES</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">SPHERES</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="n">temp_s</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">r</span> <span class="o">=</span> <span class="n">rnd</span><span class="p">(</span><span class="mf">1.0f</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">		<span class="n">temp_s</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">g</span> <span class="o">=</span> <span class="n">rnd</span><span class="p">(</span><span class="mf">1.0f</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">		<span class="n">temp_s</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">b</span> <span class="o">=</span> <span class="n">rnd</span><span class="p">(</span><span class="mf">1.0f</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">		<span class="n">temp_s</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">x</span> <span class="o">=</span> <span class="n">rnd</span><span class="p">(</span><span class="mf">1000.0f</span><span class="p">)</span> <span class="o">-</span> <span class="mi">500</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">		<span class="n">temp_s</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">y</span> <span class="o">=</span> <span class="n">rnd</span><span class="p">(</span><span class="mf">1000.0f</span><span class="p">)</span> <span class="o">-</span> <span class="mi">500</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">		<span class="n">temp_s</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">z</span> <span class="o">=</span> <span class="n">rnd</span><span class="p">(</span><span class="mf">1000.0f</span><span class="p">)</span> <span class="o">-</span> <span class="mi">500</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">		<span class="n">temp_s</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">radius</span> <span class="o">=</span> <span class="n">rnd</span><span class="p">(</span><span class="mf">100.0f</span><span class="p">)</span> <span class="o">+</span> <span class="mi">20</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//用cudaMemcpyToSymbol拷贝到常量内存
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">HANDLE_ERROR</span><span class="p">(</span><span class="n">cudaMemcpyToSymbol</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">temp_s</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="k">sizeof</span><span class="p">(</span><span class="n">Sphere</span><span class="p">)</span> <span class="o">*</span> <span class="n">SPHERES</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">	<span class="n">free</span><span class="p">(</span><span class="n">temp_s</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><ol start="3">
<li>纹理内存</li>
</ol>
<blockquote>
<p>同常量内存一样，纹理内存（Texture Memory）也是一种只读内存。 之所以称之为 “纹理”，是因为最初是为图形应用设计的。 当程序中存在大量局部空间操作时，纹理内存可以提高性能。
纹理内存的优势：
1.它们是被缓存的,如果它们在texture fetch 中将提供更高的带宽
2.它们不会像全局或常驻内存读取时受内存访问模式的约束
3.寻址计算时的延迟更低,从而提高随机访问数据时的性能
4.在一个操作中,包装的数据可以通过广播到不同的变量中
5.8-bit和16-bit的整型输入数据可以被转换成在范围[0.0,1.0]或[-1.0,1.0]的浮点数</p>
</blockquote>
<ol start="4">
<li>全局内存</li>
</ol>
<blockquote>
<p>全局内存，就是我们常说的显存，就是GDDR的空间，全局内存中的变量，只要不销毁，生命周期和应用程序是一样的。
在访问全局内存时，要求是对齐的，也就是一次要读取指定大小（32、64、128）整数倍字节的内存，数据对齐就意味着传输效率降低，比如我们想读33个字节，但实际操作中，需要读取64字节的空间。</p>
</blockquote>
<p><code>cudaMemcpy()</code> 会将主机内存复制到全局内存，而<code>cudaMemcpyToSymbol()</code> 会将主机内存复制到常量内存。</p>
<h3 id="cuda编程原则"><a href="#cuda编程原则" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:cuda编程原则" class="headings">cuda编程原则</a></h3>
<ol>
<li>避免线程发散</li>
</ol>
<p>要避免线程发散的程序：</p>
<p>若将：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">while</span> <span class="p">(</span><span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="p">(</span><span class="n">cacheIndex</span> <span class="o">&lt;</span> <span class="n">i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">			<span class="n">cache</span><span class="p">[</span><span class="n">cacheIndex</span><span class="p">]</span> <span class="o">+=</span> <span class="n">cache</span><span class="p">[</span><span class="n">cacheIndex</span> <span class="o">+</span> <span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">		<span class="n">__syncthreads</span><span class="p">();</span> 
</span></span><span class="line"><span class="cl">		<span class="n">i</span> <span class="o">/=</span> <span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>改为：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">while</span> <span class="p">(</span><span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="p">(</span><span class="n">cacheIndex</span> <span class="o">&lt;</span> <span class="n">i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="n">cache</span><span class="p">[</span><span class="n">cacheIndex</span><span class="p">]</span> <span class="o">+=</span> <span class="n">cache</span><span class="p">[</span><span class="n">cacheIndex</span> <span class="o">+</span> <span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">		    <span class="n">__syncthreads</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="cl">		<span class="n">i</span> <span class="o">/=</span> <span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>则是错误的，因为不能保证<code>cacheIndex &lt; i</code>对每个线程都成立。</p>
<p>尽量也要避免在kernel做条件判断，使得不同线程可能执行不同操作。</p>
<ol start="2">
<li>要关注代码性能</li>
</ol>
<p>使用<code>Even</code>测量代码性能</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">cudaEvent_t</span>     <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">start</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stop</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="o">*****************</span>
</span></span><span class="line"><span class="cl"><span class="err">在</span><span class="n">GPU上执行一些工作</span><span class="err">（包括前后的设备内存复制）</span>
</span></span><span class="line"><span class="cl"><span class="o">*****************</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaEventSynchronize</span><span class="p">(</span><span class="n">stop</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="kt">float</span>   <span class="n">elapsedTime</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaEventElapsedTime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">elapsedTime</span><span class="p">,</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">printf</span><span class="p">(</span><span class="s">&#34;Time to generate:  %3.1f ms</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">elapsedTime</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">cudaEventDestroy</span><span class="p">(</span><span class="n">start</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaEventDestroy</span><span class="p">(</span><span class="n">stop</span><span class="p">);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><ol start="3">
<li>
<p>所有在同一个线程块上的线程必然会在同一时间运行在同一个SM上</p>
</li>
<li>
<p>同一个内核的所有线程块必然会全部完成了后，才会运行下一个内核</p>
</li>
<li>
<p>线程同步</p>
</li>
</ol>
<p>不同的线程在共享和全局内存中读写数据需要有先后的控制，所以引入了同步性的概念。</p>
<p><img src="https://i.loli.net/2021/05/14/q1TX43pwShjBvk8.png" alt="Screenshot from 2021-05-14 11-20-41.png"><span class="caption">◎ 同步</span></p>
<blockquote>
<p>_syncthreads（）:线程块内线程同步
_threadfence(): 一个线程调用__threadfence后，该线程在该语句前对全局存储器或共享存储器的访问已经全部完成，执行结果对grid中的所有线程可见。
_threadfence_block(): 一个线程调用__threadfence_block后，该线程在该语句前对全局存储器或者共享存储器的访问已经全部完成，执行结果对block中的所有线程可见。
以上两个函数的重要作用是，及时通知其他线程，全局内存或者共享内存内的结果已经读入或写入完成了。</p>
</blockquote>
<ol start="6">
<li>最大化计算强度</li>
</ol>
<p>意味着要最大化每个线程的计算量和最小化每个线程的内存读取速度</p>
<ol start="7">
<li>原子操作</li>
</ol>
<p>对于有很多线程需要同时读取或写入相同的内存时，保证同一时间只有一个线程能进行操作。
只支持某些运算(加、减、最小值、异或运算等，不支持求余和求幂等)和数据类型（整型）</p>
<p><img src="https://i.loli.net/2021/05/14/7w1V3ZmArQFfGRt.png" alt="Screenshot from 2021-05-14 15-27-14.png"><span class="caption">◎ 各种原子操作</span></p>
<p>举个例子，假设我们想要用GPU统计“char data_0[32] = {1,0, … ,1}”这个数组中“0”和“1”的个数并写入“int counter[2]”中。</p>
<p>如果我们不使用原子操作，直接在核函数中这样写：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">extern</span> <span class="s">&#34;C&#34;</span> <span class="n">__global__</span> <span class="kt">void</span> <span class="n">kernel_func</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span> <span class="n">counter</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span> <span class="n">data_0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 计算线程号
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">block_index</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">z</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">thread_index</span> <span class="o">=</span> <span class="n">block_index</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">z</span> <span class="o">+</span> \
</span></span><span class="line"><span class="cl">        <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// 统计结果
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="n">data_0</span><span class="p">[</span><span class="n">thread_index</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="n">counter</span><span class="p">[</span><span class="n">value</span><span class="p">]</span> <span class="o">++</span><span class="p">;</span>  
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>我们会发现结果是“counter[2] = {1, 1}”，这显然不是正确的结果。
正确的写法是：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">extern</span> <span class="s">&#34;C&#34;</span> <span class="n">__global__</span> <span class="kt">void</span> <span class="n">kernel_func</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span> <span class="n">counter</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span> <span class="n">data_0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 计算线程号
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">block_index</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">z</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">thread_index</span> <span class="o">=</span> <span class="n">block_index</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">z</span> <span class="o">+</span> \
</span></span><span class="line"><span class="cl">        <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">z</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// 统计结果
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="n">data_0</span><span class="p">[</span><span class="n">thread_index</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">counter</span><span class="p">[</span><span class="n">value</span><span class="p">],</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><ol start="8">
<li>CUDA流Streams</li>
</ol>
<blockquote>
<p>用到CUDA的程序一般需要处理海量的数据，内存带宽经常会成为主要的瓶颈。在Stream的帮助下，CUDA程序可以有效地将内存读取和数值运算并行，从而提升数据的吞吐量。</p>
</blockquote>
<p>cudaStreams 有效的原因, 在nvidia gpu中：</p>
<blockquote>
<p>数据拷贝和数值计算可以同时进行。
两个方向的拷贝可以同时进行（GPU到CPU，和CPU到GPU），数据如同行驶在双向快车道。</p>
</blockquote>
<p>这样，使用一个Stream搬移大量数据，由于内存带宽有限，速度可能没有把数据切块，用多个Streams来搬移的速度块。当然，这是在gpu的运算单元没有全被占用的情况下是成立的。</p>
<blockquote>
<p>定义流：cudaStream_t s1;
创建流：cudaStreamCreate(&amp;s1);
销毁流：cudaStreamDestory(s1);</p>
</blockquote>
<p>使用八个Streams来优化：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="kt">uint8_t</span><span class="o">*</span> <span class="n">bgraBuffer</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">uint8_t</span><span class="o">*</span> <span class="n">yuvBuffer</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">uint8_t</span><span class="o">*</span> <span class="n">deviceBgraBuffer</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">uint8_t</span><span class="o">*</span> <span class="n">deviceYuvBuffer</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">int</span> <span class="n">dataSizeBgra</span> <span class="o">=</span> <span class="mi">7680</span> <span class="o">*</span> <span class="mi">4320</span> <span class="o">*</span> <span class="mi">4</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">int</span> <span class="n">dataSizeYuv</span> <span class="o">=</span> <span class="mi">7680</span> <span class="o">*</span> <span class="mi">4320</span> <span class="o">*</span> <span class="mi">3</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">cudaMallocHost</span><span class="p">(</span><span class="o">&amp;</span><span class="n">bgraBuffer</span><span class="p">,</span> <span class="n">dataSizeBgra</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaMallocHost</span><span class="p">(</span><span class="o">&amp;</span><span class="n">yuvBuffer</span><span class="p">,</span> <span class="n">dataSizeYuv</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceBgraBuffer</span><span class="p">,</span> <span class="n">dataSizeBgra</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceYuvBuffer</span><span class="p">,</span> <span class="n">dataSizeYuv</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//随机生成8K的BGRA图像
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">GenerateBgra8K</span><span class="p">(</span><span class="n">bgraBuffer</span><span class="p">,</span> <span class="n">dataSizeBgra</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//Stream的数量，这里用8个
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">const</span> <span class="kt">int</span> <span class="n">nStreams</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//Stream的初始化
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">cudaStream_t</span> <span class="n">streams</span><span class="p">[</span><span class="n">nStreams</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">nStreams</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//计算每个Stream处理的数据量。这里只是简单将数据分成8等分
</span></span></span><span class="line"><span class="cl"><span class="c1">//这里不会出现不能整除的情况，但实际中要小心
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">int</span> <span class="n">brgaOffset</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">yuvOffset</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">int</span> <span class="n">brgaChunkSize</span> <span class="o">=</span> <span class="n">dataSizeBgra</span> <span class="o">/</span> <span class="n">nStreams</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">int</span> <span class="n">yuvChunkSize</span> <span class="o">=</span> <span class="n">dataSizeYuv</span> <span class="o">/</span> <span class="n">nStreams</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//这个循环依次启动 nStreams 个 Stream
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">nStreams</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="n">brgaOffset</span> <span class="o">=</span> <span class="n">brgaChunkSize</span><span class="o">*</span><span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">yuvOffset</span> <span class="o">=</span> <span class="n">yuvChunkSize</span><span class="o">*</span><span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">//CPU到GPU的数据拷贝（原始数据），Stream i
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">cudaMemcpyAsync</span><span class="p">(</span>  <span class="n">deviceBgraBuffer</span><span class="o">+</span><span class="n">brgaOffset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">bgraBuffer</span><span class="o">+</span><span class="n">brgaOffset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">brgaChunkSize</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">//数值计算，Stream i
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">convertPixelFormat</span><span class="o">&lt;&lt;&lt;</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                                 <span class="n">deviceBgraBuffer</span><span class="o">+</span><span class="n">brgaOffset</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                 <span class="n">deviceYuvBuffer</span><span class="o">+</span><span class="n">yuvOffset</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                 <span class="n">brgaChunkSize</span><span class="o">/</span><span class="mi">4</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">//GPU到CPU的数据拷贝（计算结果），Stream i
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">cudaMemcpyAsync</span><span class="p">(</span>  <span class="n">yuvBuffer</span><span class="o">+</span><span class="n">yuvOffset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">deviceYuvBuffer</span><span class="o">+</span><span class="n">yuvOffset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">yuvChunkSize</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">cudaMemcpyDeviceToHost</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//等待所有操作完成
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">cudaFreeHost</span><span class="p">(</span><span class="n">bgraBuffer</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaFreeHost</span><span class="p">(</span><span class="n">yuvBuffer</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaFree</span><span class="p">(</span><span class="n">deviceBgraBuffer</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">cudaFree</span><span class="p">(</span><span class="n">deviceYuvBuffer</span><span class="p">);</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><p>详细代码看<a href="https://zhuanlan.zhihu.com/p/51402722" target="_blank" rel="noopener">CUDA随笔之Stream的使用</a>， 讲的很详细。</p>
<h2 id="练习代码"><a href="#练习代码" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:练习代码" class="headings">练习代码</a></h2>
<p>可以参考<a href="https://gitee.com/jiajiewu/cuda_practice.git" target="_blank" rel="noopener">cuda_practice</a> ，熟悉opencv和cuda联合编程的几个例子。</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="cm">/****************************1. 并行编程的基础知识***********************************/</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//1. hello cuda
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">showhello</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c1">//2. 矩阵相乘
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">showMatMul</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c1">//3. 求平方
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">showsquare</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c1">//4. 多数之和 输入参数0：使用全局内存 输入参数1：使用共享内存
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">showreduce</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="c1">//5. 数组扫描 更新数组，每一个数组的值是前面所有遍历过的数组的值之和 输入参数0：使用全局内存 输入参数1：使用共享内存
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">showscan</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//上面两个例子的global memory 都比 share memory 的时间小，不太懂为什么，是跑的数据量比较小吗
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">	<span class="c1">//6. 分段直方图统计 输入参数0：错误示范 输入参数1：不分段，适用于bin数比较多的情况 输入参数2：分段，适用于bin数比较少的情况
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">//分段直方图思想：假设开的线程数是THREADS_COUNT，直方图分组的数是BIN_COUNT；
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">//每个线程不只处理一个数据，而是平均地处理ARRAY_SIZE/THREADS_COUNT个数据。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">//这时需要创建一个THREADS_COUNT×BIN_COUNT×sizeof(int)的共享内存，每个线程处理ARRAY_SIZE/THREADS_COUNT个数据，然后把结果放在
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">//BIN_COUNT×sizeof(int)的共享内存里面；将所有数据处理完后再做一次reduce即可。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="c1">//速度比不分段的慢，但开的线程很少，节省资源
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">showhisto</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">	<span class="cm">/*****************************2. 图像处理中的并行编程基础**********************************/</span>
</span></span><span class="line"><span class="cl">        <span class="c1">//7. 彩色图转灰度图
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">showrgb2grey</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//8. 均值滤波
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">showblur</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">	<span class="c1">//9. 图像翻转
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>	<span class="n">showreverse</span><span class="p">();</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div>
            </div>

            
    
    
        <ul class="post-copyright">
            <li class="copyright-item author"><span class="copyright-item-text">作者</span>：<a href="https://www.jiajiewu.top/" class="p-author h-card" target="_blank" rel="noopener">JiaJie</a></li>
            
                
                
                
                
                <li class="copyright-item link"><span class="copyright-item-text">链接</span>：<a href="/contents/cuda/cuda_more/" target="_blank" rel="noopener">https://wjiajie.github.io/contents/cuda/cuda_more/</a></li>
            
            <li class="copyright-item license"><span class="copyright-item-text">许可</span>：<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a></li>
            
        </ul>
    



        </article>

        

        
    <div class="updated-badge-container">
        <span title="Updated @ 2021-05-14 09:09:40 CST" style="cursor:help">

<svg xmlns="http://www.w3.org/2000/svg" width="130" height="20" class="updated-badge"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#a)"><path class="updated-badge-left" d="M0 0h55v20H0z"/><path class="updated-badge-right" d="M55 0h75v20H55z"/><path fill="url(#b)" d="M0 0h130v20H0z"/></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2021-05-14</text><text x="915" y="140" textLength="650" transform="scale(.1)">2021-05-14</text></g></svg>
        </span></div>



        


        <div class="post-share">

        

        <div class="share-items">

            
            
                
                    <div class="share-item facebook">
                        
                        <a href="https://www.facebook.com/sharer/sharer.php?u=https://wjiajie.github.io/contents/cuda/cuda_more/&amp;hashtag=%23%e9%ab%98%e6%80%a7%e8%83%bd%e7%bc%96%e7%a8%8b" title="分享到「Facebook」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon facebook-icon"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg></a>
                    </div>
                
            
                
                    <div class="share-item twitter">
                        
                        <a href="https://twitter.com/share?url=https://wjiajie.github.io/contents/cuda/cuda_more/&amp;text=%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0&amp;hashtags=%e9%ab%98%e6%80%a7%e8%83%bd%e7%bc%96%e7%a8%8b,cuda,&amp;via=" title="分享到「Twitter」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon twitter-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                    </div>
                
            
                
                    <div class="share-item linkedin">
                        
                        <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://wjiajie.github.io/contents/cuda/cuda_more/&amp;title=%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0&amp;summary=%e6%9c%ac%e6%96%87%e4%b8%bb%e8%a6%81%e8%ae%b0%e5%bd%95%e5%9c%a8%e5%ad%a6%e4%b9%a0%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e8%bf%87%e7%a8%8b%e4%b8%ad%e7%9a%84%e7%9f%a5%e8%af%86%e8%a6%81%e7%82%b9%ef%bc%8c%e5%b9%b6%e4%b8%94%e6%8a%8a%e8%b7%91%e8%bf%87%e7%9a%84%e4%bb%a3%e7%a0%81%e7%bb%9f%e4%b8%80%e6%94%be%e5%9c%a8cmake%e5%b7%a5%e7%a8%8b%e9%87%8c%e9%9d%a2%e3%80%82%0a%e5%85%b3%e4%ba%8ecuda%e6%9b%b4%e5%85%b7%e4%bd%93%e7%9a%84%e4%bb%8b%e7%bb%8d%ef%bc%8c%e4%b8%80%e4%b8%aa%e5%8d%9a%e5%ae%a2%e4%b8%93%e9%a2%98%e4%bb%8b%e7%bb%8d%e7%9a%84%e5%be%88%e5%a5%bd%ef%bc%9a%20CUDA%e4%bb%8e%e5%85%a5%e9%97%a8%e5%88%b0%e5%85%a5%e9%97%a8%0a%e5%af%b9%e5%ba%94%e7%9a%84%e4%bb%a3%e7%a0%81%e5%9c%a8%ef%bc%9a%20https://github.com/Tony-Tan/CUDA_Freshman%0a%e2%80%a6%e2%80%a6&amp;source=W" title="分享到「LinkedIn」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon linkedin-icon"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
                    </div>
                
            
                
                    <div class="share-item telegram">
                        
                        <a href="https://t.me/share/url?url=https://wjiajie.github.io/contents/cuda/cuda_more/&amp;text=%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0" title="分享到「Telegram」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon telegram-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                    </div>
                
            
                
                    <div class="share-item qq">
                        
                        <a href="https://connect.qq.com/widget/shareqq/index.html?url=https://wjiajie.github.io/contents/cuda/cuda_more/&amp;title=%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0&amp;summary=%e6%9c%ac%e6%96%87%e4%b8%bb%e8%a6%81%e8%ae%b0%e5%bd%95%e5%9c%a8%e5%ad%a6%e4%b9%a0%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e8%bf%87%e7%a8%8b%e4%b8%ad%e7%9a%84%e7%9f%a5%e8%af%86%e8%a6%81%e7%82%b9%ef%bc%8c%e5%b9%b6%e4%b8%94%e6%8a%8a%e8%b7%91%e8%bf%87%e7%9a%84%e4%bb%a3%e7%a0%81%e7%bb%9f%e4%b8%80%e6%94%be%e5%9c%a8cmake%e5%b7%a5%e7%a8%8b%e9%87%8c%e9%9d%a2%e3%80%82%0a%e5%85%b3%e4%ba%8ecuda%e6%9b%b4%e5%85%b7%e4%bd%93%e7%9a%84%e4%bb%8b%e7%bb%8d%ef%bc%8c%e4%b8%80%e4%b8%aa%e5%8d%9a%e5%ae%a2%e4%b8%93%e9%a2%98%e4%bb%8b%e7%bb%8d%e7%9a%84%e5%be%88%e5%a5%bd%ef%bc%9a%20CUDA%e4%bb%8e%e5%85%a5%e9%97%a8%e5%88%b0%e5%85%a5%e9%97%a8%0a%e5%af%b9%e5%ba%94%e7%9a%84%e4%bb%a3%e7%a0%81%e5%9c%a8%ef%bc%9a%20https://github.com/Tony-Tan/CUDA_Freshman%0a%e2%80%a6%e2%80%a6&amp;pics=https://i.loli.net/2019/05/25/5ce8acf85ef8e11960.png&amp;site=W" title="分享到「QQ」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qq-icon"><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z"/></svg></a>
                    </div>
                
            
                
                    <div class="share-item qzone">
                        
                        <a href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://wjiajie.github.io/contents/cuda/cuda_more/&amp;title=%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0&amp;summary=%e6%9c%ac%e6%96%87%e4%b8%bb%e8%a6%81%e8%ae%b0%e5%bd%95%e5%9c%a8%e5%ad%a6%e4%b9%a0%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e8%bf%87%e7%a8%8b%e4%b8%ad%e7%9a%84%e7%9f%a5%e8%af%86%e8%a6%81%e7%82%b9%ef%bc%8c%e5%b9%b6%e4%b8%94%e6%8a%8a%e8%b7%91%e8%bf%87%e7%9a%84%e4%bb%a3%e7%a0%81%e7%bb%9f%e4%b8%80%e6%94%be%e5%9c%a8cmake%e5%b7%a5%e7%a8%8b%e9%87%8c%e9%9d%a2%e3%80%82%0a%e5%85%b3%e4%ba%8ecuda%e6%9b%b4%e5%85%b7%e4%bd%93%e7%9a%84%e4%bb%8b%e7%bb%8d%ef%bc%8c%e4%b8%80%e4%b8%aa%e5%8d%9a%e5%ae%a2%e4%b8%93%e9%a2%98%e4%bb%8b%e7%bb%8d%e7%9a%84%e5%be%88%e5%a5%bd%ef%bc%9a%20CUDA%e4%bb%8e%e5%85%a5%e9%97%a8%e5%88%b0%e5%85%a5%e9%97%a8%0a%e5%af%b9%e5%ba%94%e7%9a%84%e4%bb%a3%e7%a0%81%e5%9c%a8%ef%bc%9a%20https://github.com/Tony-Tan/CUDA_Freshman%0a%e2%80%a6%e2%80%a6&amp;pics=https://i.loli.net/2019/05/25/5ce8acf85ef8e11960.png&amp;site=W" title="分享到「QQ 空间」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon qzone-icon"><path d="M23.985 9.202c-.032-.099-.127-.223-.334-.258-.207-.036-7.351-1.406-7.351-1.406s-.105-.022-.198-.07c-.092-.047-.127-.167-.127-.167S12.447.956 12.349.77C12.25.583 12.104.532 12 .532c-.104 0-.251.051-.349.238-.098.186-3.626 6.531-3.626 6.531s-.035.12-.128.167c-.092.047-.197.07-.197.07S.556 8.908.348 8.943c-.208.036-.302.16-.333.258a.477.477 0 0 0 .125.449l5.362 5.49s.072.08.119.172c.016.104.005.21.005.21s-1.189 7.242-1.22 7.45.075.369.159.43c.083.062.233.106.421.013.189-.093 6.812-3.261 6.812-3.261s.098-.044.201-.061c.103-.017.201.061.201.061s6.623 3.168 6.812 3.261c.188.094.338.049.421-.013a.463.463 0 0 0 .159-.43c-.021-.14-.93-5.677-.93-5.677.876-.54 1.425-1.039 1.849-1.747-2.594.969-6.006 1.717-9.415 1.866-.915.041-2.41.097-3.473-.015-.678-.071-1.17-.144-1.243-.438-.053-.215.054-.46.545-.831a2640.5 2640.5 0 0 1 2.861-2.155c1.285-.968 3.559-2.47 3.559-2.731 0-.285-2.144-.781-4.037-.781-1.945 0-2.275.132-2.811.168-.488.034-.769.005-.804-.138-.06-.248.183-.389.588-.568.709-.314 1.86-.594 1.984-.626.194-.052 3.082-.805 5.618-.535 1.318.14 3.244.668 3.244 1.276 0 .342-1.721 1.494-3.225 2.597-1.149.843-2.217 1.561-2.217 1.688 0 .342 3.533 1.241 6.689 1.01l.003-.022c.048-.092.119-.172.119-.172l5.362-5.49a.477.477 0 0 0 .127-.449z"/></svg></a>
                    </div>
                
            
                
                    <div class="share-item qrcode">
                        <div class="qrcode-container" title="通过「二维码」"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qrcode-icon"><path d="M0 224h192V32H0v192zM64 96h64v64H64V96zm192-64v192h192V32H256zm128 128h-64V96h64v64zM0 480h192V288H0v192zm64-128h64v64H64v-64zm352-64h32v128h-96v-32h-32v96h-64V288h96v32h64v-32zm0 160h32v32h-32v-32zm-64 0h32v32h-32v-32z"/></svg><div id="qrcode-img"></div>
                        </div>
                        <script src="https://cdn.jsdelivr.net/npm/qrcode-generator@1.4.4/qrcode.min.js"></script>

<script>
    const typeNumber = 0;
    const errorCorrectionLevel = 'L';
    const qr = qrcode(typeNumber, errorCorrectionLevel);
    qr.addData('https:\/\/wjiajie.github.io\/contents\/cuda\/cuda_more\/');
    qr.make();
    document.getElementById('qrcode-img').innerHTML = qr.createImgTag();
</script>

                    </div>
                
            
                
                    <div class="share-item email">
                        
                        <a href="mailto:?subject=%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0&amp;body=%e6%9c%ac%e6%96%87%e4%b8%bb%e8%a6%81%e8%ae%b0%e5%bd%95%e5%9c%a8%e5%ad%a6%e4%b9%a0%e3%80%8aGPU%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e4%b8%8eCUDA%e7%bc%96%e7%a8%8b%e3%80%8b%e8%bf%87%e7%a8%8b%e4%b8%ad%e7%9a%84%e7%9f%a5%e8%af%86%e8%a6%81%e7%82%b9%ef%bc%8c%e5%b9%b6%e4%b8%94%e6%8a%8a%e8%b7%91%e8%bf%87%e7%9a%84%e4%bb%a3%e7%a0%81%e7%bb%9f%e4%b8%80%e6%94%be%e5%9c%a8cmake%e5%b7%a5%e7%a8%8b%e9%87%8c%e9%9d%a2%e3%80%82%0a%e5%85%b3%e4%ba%8ecuda%e6%9b%b4%e5%85%b7%e4%bd%93%e7%9a%84%e4%bb%8b%e7%bb%8d%ef%bc%8c%e4%b8%80%e4%b8%aa%e5%8d%9a%e5%ae%a2%e4%b8%93%e9%a2%98%e4%bb%8b%e7%bb%8d%e7%9a%84%e5%be%88%e5%a5%bd%ef%bc%9a%20CUDA%e4%bb%8e%e5%85%a5%e9%97%a8%e5%88%b0%e5%85%a5%e9%97%a8%0a%e5%af%b9%e5%ba%94%e7%9a%84%e4%bb%a3%e7%a0%81%e5%9c%a8%ef%bc%9a%20https://github.com/Tony-Tan/CUDA_Freshman%0a%e2%80%a6%e2%80%a6%0Ahttps://wjiajie.github.io/contents/cuda/cuda_more/" title="通过" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon email-icon"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg></a>
                    </div>
                
            
        </div>

    </div>




        
    
    
        <div class="related-posts">
            <h2 class="related-title">相关文章：<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon related-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm144 276c0 6.6-5.4 12-12 12h-92v92c0 6.6-5.4 12-12 12h-56c-6.6 0-12-5.4-12-12v-92h-92c-6.6 0-12-5.4-12-12v-56c0-6.6 5.4-12 12-12h92v-92c0-6.6 5.4-12 12-12h56c6.6 0 12 5.4 12 12v92h92c6.6 0 12 5.4 12 12v56z"/></svg></h2>
            <ul class="related-list">
                
                    <li class="related-item">
                        <a href="/contents/cuda/cuda-practice5/" class="related-link">cuda学习笔记5</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/contents/cuda/cuda-practice4/" class="related-link">cuda学习笔记4</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/contents/cuda/cuda-practice3/" class="related-link">cuda学习笔记3</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/contents/cuda/cuda-practice2/" class="related-link">cuda学习笔记2</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/contents/cuda/cuda-practice1/" class="related-link">cuda学习笔记1</a>
                    </li>
                
            </ul>
        </div>
    



        
    
        <div class="post-tags">
            
                
                
                
                
                    
                    <a href="/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>高性能编程</a>
                
            
                
                
                
                
                    
                    <a href="/tags/cuda/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>cuda</a>
                
            
        </div>
    



        


        


        
    
        
        
    
    
    
    
        <ul class="post-nav">
            
            
                <li class="post-nav-next">
                    <a href="/contents/cuda/cuda-practice5/" rel="next">cuda学习笔记5 &gt;</a>
                </li>
            
        </ul>
    



        
    

        

        

        

        
            <div id="utterances"></div>
        

        
    



    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            
    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="site-info">2019–2023&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;JiaJie</div>

            
    
        <ul class="socials"><li class="socials-item">
                    <a href="https://applink.feishu.cn/client/chat/chatter/add_by_link?link_token=4f5pfeb3-46f6-4c97-9572-c4698314d3ac" target="_blank" rel="external noopener" title="飞书[Lark]"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M301.1 212c4.4 4.4 4.4 11.9 0 16.3l-9.7 9.7c-4.4 4.7-11.9 4.7-16.6 0l-10.5-10.5c-4.4-4.7-4.4-11.9 0-16.6l9.7-9.7c4.4-4.4 11.9-4.4 16.6 0l10.5 10.8zm-30.2-19.7c3-3 3-7.8 0-10.5-2.8-3-7.5-3-10.5 0-2.8 2.8-2.8 7.5 0 10.5 3.1 2.8 7.8 2.8 10.5 0zm-26 5.3c-3 2.8-3 7.5 0 10.2 2.8 3 7.5 3 10.5 0 2.8-2.8 2.8-7.5 0-10.2-3-3-7.7-3-10.5 0zm72.5-13.3c-19.9-14.4-33.8-43.2-11.9-68.1 21.6-24.9 40.7-17.2 59.8.8 11.9 11.3 29.3 24.9 17.2 48.2-12.5 23.5-45.1 33.2-65.1 19.1zm47.7-44.5c-8.9-10-23.3 6.9-15.5 16.1 7.4 9 32.1 2.4 15.5-16.1zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-66.2 42.6c2.5-16.1-20.2-16.6-25.2-25.7-13.6-24.1-27.7-36.8-54.5-30.4 11.6-8 23.5-6.1 23.5-6.1.3-6.4 0-13-9.4-24.9 3.9-12.5.3-22.4.3-22.4 15.5-8.6 26.8-24.4 29.1-43.2 3.6-31-18.8-59.2-49.8-62.8-22.1-2.5-43.7 7.7-54.3 25.7-23.2 40.1 1.4 70.9 22.4 81.4-14.4-1.4-34.3-11.9-40.1-34.3-6.6-25.7 2.8-49.8 8.9-61.4 0 0-4.4-5.8-8-8.9 0 0-13.8 0-24.6 5.3 11.9-15.2 25.2-14.4 25.2-14.4 0-6.4-.6-14.9-3.6-21.6-5.4-11-23.8-12.9-31.7 2.8.1-.2.3-.4.4-.5-5 11.9-1.1 55.9 16.9 87.2-2.5 1.4-9.1 6.1-13 10-21.6 9.7-56.2 60.3-56.2 60.3-28.2 10.8-77.2 50.9-70.6 79.7.3 3 1.4 5.5 3 7.5-2.8 2.2-5.5 5-8.3 8.3-11.9 13.8-5.3 35.2 17.7 24.4 15.8-7.2 29.6-20.2 36.3-30.4 0 0-5.5-5-16.3-4.4 27.7-6.6 34.3-9.4 46.2-9.1 8 3.9 8-34.3 8-34.3 0-14.7-2.2-31-11.1-41.5 12.5 12.2 29.1 32.7 28 60.6-.8 18.3-15.2 23-15.2 23-9.1 16.6-43.2 65.9-30.4 106 0 0-9.7-14.9-10.2-22.1-17.4 19.4-46.5 52.3-24.6 64.5 26.6 14.7 108.8-88.6 126.2-142.3 34.6-20.8 55.4-47.3 63.9-65 22 43.5 95.3 94.5 101.1 59z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://chat.google.com/room/AAAA6JWtXbI?cls=7" target="_blank" rel="external noopener" title="Gmail Spaces"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://sm.ms/image/8nvJgfqrFkDLObK" target="_blank" rel="external noopener" title="微信[Wechat]"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon social-icon"><path d="M0 224h192V32H0v192zM64 96h64v64H64V96zm192-64v192h192V32H256zm128 128h-64V96h64v64zM0 480h192V288H0v192zm64-128h64v64H64v-64zm352-64h32v128h-96v-32h-32v96h-64V288h96v32h64v-32zm0 160h32v32h-32v-32zm-64 0h32v32h-32v-32z"/></svg></a>
                </li></ul>
    



            

<div class="container" role="main" itemscope itemtype="http://schema.org/Article">
    <div class="row">
        <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
           
            <article role="main" class="blog-post" itemprop="articleBody" id="content">
              
                
                
                <div class="social-share" data-initialized="true" data-wechat-qrcode-title="扫一扫分享到微信">
    <center>
    <font style="font-size:18px;color:darkcyan;">分享到：</font>
    <a href=" " class="social-share-icon icon-weibo"></a >
    <a href="#" class="social-share-icon icon-wechat"></a >
    <a href="#" class="social-share-icon icon-twitter"></a >
    <a href="#" class="social-share-icon icon-linkedin"></a >
    <a href="#" class="social-share-icon icon-facebook"></a >
    <a href="#" class="social-share-icon icon-qq"></a >
    <a href="#" class="social-share-icon icon-qzone"></a >
    </center>
</div>


<link rel="stylesheet" href="https://wjiajie.github.io/css/share.min.css" />
<script src="https://hugo-picture.oss-cn-beijing.aliyuncs.com/social-share.min.js"></script>

                
                
            </article>



        </div>
    </footer>


        </div>
        

        


    <script>
    if (typeof MathJax === 'undefined') {
        window.MathJax = {
            loader: {
                load: ['[tex]/mhchem']
            },
            
            tex: {
                inlineMath: {'[+]': [['$', '$']]},
                tags: 'ams',
                packages: {'[+]': ['mhchem']}
            }
        };
        (function() {
            const script = document.createElement('script');
            script.src = 'https:\/\/cdn.jsdelivr.net\/npm\/mathjax@3.1.2\/es5\/tex-mml-chtml.js';
            script.defer = true;
            document.head.appendChild(script);
        })();
    } else {
        MathJax.texReset();
        MathJax.typeset();
    }
</script>






    

        

        

        
            <script>
    function loadComments() {
        (function() {
            const utterances = document.getElementById("utterances");
            if (!utterances) {
                return;
            }
            const script = document.createElement('script');
            script.src = 'https:\/\/utteranc.es\/client.js';
            script.async = true;
            script.crossOrigin = 'anonymous';
            script.setAttribute('repo', 'Wjiajie\/Wjiajie.github.io');
            script.setAttribute('issue-term', 'pathname');
            const isDark = getCurrentTheme() === 'dark';
        if (isDark) {
            script.setAttribute('theme', 'photon-dark');
        } else {
            script.setAttribute('theme', 'github-light');
        }
            
            utterances.appendChild(script);
        })();
    }
</script>
        

        

    



    <script src="/js/medium-zoom.min.js"></script>

<script>
    mediumZoom(document.querySelectorAll('div.post-body img'), {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module" defer></script>






    </body>
</html>
